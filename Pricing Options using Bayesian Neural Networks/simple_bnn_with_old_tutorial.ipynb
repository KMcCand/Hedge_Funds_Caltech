{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e677baf",
   "metadata": {
    "id": "9e677baf"
   },
   "source": [
    "# Pricing Options using Bayesian Neural Networks\n",
    "## Old version -- BNN implementation was too naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55922e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ec4948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE:\n",
    "# https://www.codearmo.com/python-tutorial/options-trading-black-scholes-model\n",
    "\n",
    "N = norm.cdf\n",
    "\n",
    "def BS_CALL(S, K, T, r, sigma):\n",
    "    d1 = (np.log(S/K) + (r + sigma**2/2)*T) / (sigma*np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "    return S * N(d1) - K * np.exp(-r*T)* N(d2)\n",
    "\n",
    "def BS_PUT(S, K, T, r, sigma):\n",
    "    d1 = (np.log(S/K) + (r + sigma**2/2)*T) / (sigma*np.sqrt(T))\n",
    "    d2 = d1 - sigma* np.sqrt(T)\n",
    "    return K*np.exp(-r*T)*N(-d2) - S*N(-d1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb1c260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f800d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/24/b7637qzn5pz9_l33fc30f4240000gn/T/ipykernel_20020/1915063261.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  close_df['prev_Close'] = close_df['Close'].shift(1)\n",
      "/var/folders/24/b7637qzn5pz9_l33fc30f4240000gn/T/ipykernel_20020/1915063261.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  close_df['prev_prev_Close'] = close_df['prev_Close'].shift(1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>prev_Close</th>\n",
       "      <th>prev_prev_Close</th>\n",
       "      <th>Ret</th>\n",
       "      <th>prev_Ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1928-01-04</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>17.760000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>-0.002252</td>\n",
       "      <td>0.005663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1928-01-05</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>17.760000</td>\n",
       "      <td>-0.009594</td>\n",
       "      <td>-0.002252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1928-01-06</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>17.719999</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>-0.009594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1928-01-09</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>-0.009060</td>\n",
       "      <td>0.006268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1928-01-10</td>\n",
       "      <td>17.370001</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>17.660000</td>\n",
       "      <td>-0.007429</td>\n",
       "      <td>-0.009060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24213</th>\n",
       "      <td>2024-05-22</td>\n",
       "      <td>5307.009766</td>\n",
       "      <td>5321.410156</td>\n",
       "      <td>5308.129883</td>\n",
       "      <td>-0.002706</td>\n",
       "      <td>0.002502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24214</th>\n",
       "      <td>2024-05-23</td>\n",
       "      <td>5267.839844</td>\n",
       "      <td>5307.009766</td>\n",
       "      <td>5321.410156</td>\n",
       "      <td>-0.007381</td>\n",
       "      <td>-0.002706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24215</th>\n",
       "      <td>2024-05-24</td>\n",
       "      <td>5304.720215</td>\n",
       "      <td>5267.839844</td>\n",
       "      <td>5307.009766</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>-0.007381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24216</th>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>5306.040039</td>\n",
       "      <td>5304.720215</td>\n",
       "      <td>5267.839844</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.007001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24217</th>\n",
       "      <td>2024-05-29</td>\n",
       "      <td>5266.950195</td>\n",
       "      <td>5306.040039</td>\n",
       "      <td>5304.720215</td>\n",
       "      <td>-0.007367</td>\n",
       "      <td>0.000249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24216 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date        Close   prev_Close  prev_prev_Close       Ret  \\\n",
       "2      1928-01-04    17.719999    17.760000        17.660000 -0.002252   \n",
       "3      1928-01-05    17.549999    17.719999        17.760000 -0.009594   \n",
       "4      1928-01-06    17.660000    17.549999        17.719999  0.006268   \n",
       "5      1928-01-09    17.500000    17.660000        17.549999 -0.009060   \n",
       "6      1928-01-10    17.370001    17.500000        17.660000 -0.007429   \n",
       "...           ...          ...          ...              ...       ...   \n",
       "24213  2024-05-22  5307.009766  5321.410156      5308.129883 -0.002706   \n",
       "24214  2024-05-23  5267.839844  5307.009766      5321.410156 -0.007381   \n",
       "24215  2024-05-24  5304.720215  5267.839844      5307.009766  0.007001   \n",
       "24216  2024-05-28  5306.040039  5304.720215      5267.839844  0.000249   \n",
       "24217  2024-05-29  5266.950195  5306.040039      5304.720215 -0.007367   \n",
       "\n",
       "       prev_Ret  \n",
       "2      0.005663  \n",
       "3     -0.002252  \n",
       "4     -0.009594  \n",
       "5      0.006268  \n",
       "6     -0.009060  \n",
       "...         ...  \n",
       "24213  0.002502  \n",
       "24214 -0.002706  \n",
       "24215 -0.007381  \n",
       "24216  0.007001  \n",
       "24217  0.000249  \n",
       "\n",
       "[24216 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('^SPX.csv')\n",
    "\n",
    "close_df = df[['Date', 'Close']]\n",
    "close_df['prev_Close'] = close_df['Close'].shift(1)\n",
    "close_df['prev_prev_Close'] = close_df['prev_Close'].shift(1)\n",
    "\n",
    "close_df = close_df.dropna(subset=['prev_prev_Close'])\n",
    "close_df = close_df.astype({'Close': 'double', 'prev_Close': 'double'})\n",
    "\n",
    "close_df['Ret'] = close_df['Close'] / close_df['prev_Close'] - 1\n",
    "close_df['prev_Ret'] = close_df['prev_Close'] / close_df['prev_prev_Close'] - 1\n",
    "\n",
    "# Drop last row cause it is an incomplete month\n",
    "close_df.drop(close_df.tail(1).index, inplace=True)\n",
    "\n",
    "close_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6e5b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchbnn as bnn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ad60381",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.from_numpy(close_df['prev_Ret'].values)\n",
    "x = torch.unsqueeze(x_data, dim=1)\n",
    "\n",
    "y_data = torch.from_numpy(close_df['Ret'].values)\n",
    "y = torch.unsqueeze(y_data, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "66ef7ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=1, out_features=1000).double(),\n",
    "    nn.ReLU(),\n",
    "    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=1000, out_features=1).double(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1cdc5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False)\n",
    "kl_weight = 0.01\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "19b92ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- MSE : 0.06, KL : 0.71\n"
     ]
    }
   ],
   "source": [
    "for step in range(2000):\n",
    "    pre = model(x)\n",
    "    mse = mse_loss(pre, y)\n",
    "    kl = kl_loss(model)\n",
    "    cost = mse + kl_weight*kl\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print('- MSE : %2.2f, KL : %2.2f' % (mse.item(), kl.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bcb853ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_result = np.array([model(x).data.numpy() for k in range(10000)])\n",
    "models_result = models_result[:,:,0]    \n",
    "models_result = models_result.T\n",
    "mean_values = np.array([models_result[i].mean() for i in range(len(models_result))])\n",
    "std_values = np.array([models_result[i].std() for i in range(len(models_result))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cfc3d782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(x_data.numpy(),mean_values,color='navy',lw=3,label='Predicted Mean Model')\n",
    "plt.fill_between(x_data.numpy().T[0],mean_values-3.0*std_values,mean_values+3.0*std_values,alpha=0.2,color='navy',label='99.7% confidence interval')\n",
    "plt.plot(x_data.numpy(),y_data.numpy(),'.',color='darkorange',markersize=4,label='Test set')\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a61ecd7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2b6967790>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_data.numpy(), y_data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d2d5a37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(x_data, bins=50, edgecolor='black')  # Adjust the number of bins as needed\n",
    "plt.title('Histogram of Monthly Returns')\n",
    "plt.xlabel('Monthly Return')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "80c4e1dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchbnn' has no attribute 'plot_posterior'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots()\n\u001b[0;32m----> 2\u001b[0m bnn\u001b[38;5;241m.\u001b[39mplot_posterior(model, ax\u001b[38;5;241m=\u001b[39max, show_theta\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torchbnn' has no attribute 'plot_posterior'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bnn.plot_posterior(model, ax=ax, show_theta=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3469ef5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164daccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d3f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bc4b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebc9bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caae2612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db49da34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f119b23f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3421cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d61f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e410e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "765ed3e4",
   "metadata": {
    "id": "765ed3e4"
   },
   "source": [
    "## Question 0 - Run the Neural Net and Interpet the alpha\n",
    "The following code fits a feed-forward neural net on all data, and prints a summary.\n",
    "Run the code and provide an interpretation of the alpha.\n",
    "\n",
    "```\n",
    "fitting_returns_data(\n",
    "    'ff6_factors_19630701_20230131.csv',\n",
    "    io_day_1_lag,\n",
    "    model_feed_forward);\n",
    "```\n",
    "\n",
    "**Note**: The test-train split we're employing in these model fits is faulty. We use data from the future to predict our model, so all results here have some level of overfitting. However, I separately fit the models by only using past data, and we were able to get similar results, so the results still seem robust to the potential overfitting.\n",
    "\n",
    "### Question 0 Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f49a61a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f49a61a",
    "outputId": "2f1da065-7f42-4039-e7be-173330580c6c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 6ms/step - loss: 0.4313 - val_loss: 0.4482\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.4189 - val_loss: 0.4461\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4163 - val_loss: 0.4463\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4147 - val_loss: 0.4461\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4133 - val_loss: 0.4451\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4119 - val_loss: 0.4450\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4110 - val_loss: 0.4453\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4105 - val_loss: 0.4450\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4098 - val_loss: 0.4458\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4092 - val_loss: 0.4461\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4085 - val_loss: 0.4469\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4468\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.4471\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4070 - val_loss: 0.4461\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4067 - val_loss: 0.4463\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4060 - val_loss: 0.4456\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4054 - val_loss: 0.4468\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4050 - val_loss: 0.4494\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4049 - val_loss: 0.4459\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4042 - val_loss: 0.4466\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4041 - val_loss: 0.4468\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4033 - val_loss: 0.4459\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4035 - val_loss: 0.4476\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4029 - val_loss: 0.4480\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4024 - val_loss: 0.4501\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4027 - val_loss: 0.4473\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4019 - val_loss: 0.4478\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4018 - val_loss: 0.4484\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4014 - val_loss: 0.4497\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4010 - val_loss: 0.4494\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4010 - val_loss: 0.4493\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4002 - val_loss: 0.4489\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4004 - val_loss: 0.4507\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3996 - val_loss: 0.4507\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3995 - val_loss: 0.4493\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3993 - val_loss: 0.4489\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3990 - val_loss: 0.4481\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3984 - val_loss: 0.4498\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3990 - val_loss: 0.4498\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3985 - val_loss: 0.4502\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3980 - val_loss: 0.4514\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3977 - val_loss: 0.4513\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3971 - val_loss: 0.4494\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3972 - val_loss: 0.4515\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3969 - val_loss: 0.4506\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3962 - val_loss: 0.4520\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3961 - val_loss: 0.4517\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3960 - val_loss: 0.4505\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3961 - val_loss: 0.4529\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3957 - val_loss: 0.4543\n",
      "469/469 [==============================] - 1s 1ms/step\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.147\n",
      "Model:                            OLS   Adj. R-squared:                  0.147\n",
      "Method:                 Least Squares   F-statistic:                     431.8\n",
      "Date:                Sun, 19 May 2024   Prob (F-statistic):               0.00\n",
      "Time:                        03:32:53   Log-Likelihood:                -15710.\n",
      "No. Observations:               14998   AIC:                         3.143e+04\n",
      "Df Residuals:                   14991   BIC:                         3.149e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1232      0.006     21.787      0.000       0.112       0.134\n",
      "Mkt-RF         0.2080      0.006     34.344      0.000       0.196       0.220\n",
      "SMB            0.0161      0.011      1.461      0.144      -0.006       0.038\n",
      "HML            0.1985      0.013     15.628      0.000       0.174       0.223\n",
      "RMW            0.1350      0.015      8.884      0.000       0.105       0.165\n",
      "CMA            0.0336      0.020      1.724      0.085      -0.005       0.072\n",
      "MOM            0.3153      0.008     39.919      0.000       0.300       0.331\n",
      "==============================================================================\n",
      "Omnibus:                     4889.878   Durbin-Watson:                   1.938\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           291002.805\n",
      "Skew:                           0.748   Prob(JB):                         0.00\n",
      "Kurtosis:                      24.527   Cond. No.                         4.01\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "COMMON_SEED = 519\n",
    "\n",
    "# Calculate returns and alphas using feed forward neural net model\n",
    "fitting_returns_data(\n",
    "    'ff6_factors_19630701_20230131.csv',\n",
    "    io_day_1_lag,\n",
    "    model_feed_forward,\n",
    "    seed = COMMON_SEED);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d6dd8",
   "metadata": {
    "id": "d26d6dd8"
   },
   "source": [
    "The alpha value of 0.1232 is positive and significant at the 1% level, indicating that using Neural Networks to identify relationships between the six factors is a profitable hedge fund strategy.\n",
    "\n",
    "## Question 1 - Comparing Neural Net to OLS\n",
    "\n",
    "### 1ai [20 points] Set a linear activation function\n",
    "For the feed-forward neural net that is fit above, the `model_feed_forward` function sets up activation across hidden layers with the following code:\n",
    "\n",
    "```\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(6,)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(6, activation='linear'))\n",
    "```\n",
    "\n",
    "Write a new function called `model_feed_forward_linear`, which changes the `'relu'` parameter to `'linear'`.\n",
    "\n",
    "\n",
    "Calculate reults for the neural net with linear activation. How does this compare to the ReLU activation from Question 0?\n",
    "\n",
    "### Solution 1ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1106235",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1106235",
    "outputId": "47166348-22b3-46b5-8089-9bad93dd7257"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 2ms/step - loss: 0.4409 - val_loss: 0.4450\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4226 - val_loss: 0.4450\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4217 - val_loss: 0.4446\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4206 - val_loss: 0.4527\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4213 - val_loss: 0.4448\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4201 - val_loss: 0.4466\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4205 - val_loss: 0.4462\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4211 - val_loss: 0.4473\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4197 - val_loss: 0.4479\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4198 - val_loss: 0.4540\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4209 - val_loss: 0.4475\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4196 - val_loss: 0.4488\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4201 - val_loss: 0.4453\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4195 - val_loss: 0.4537\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4204 - val_loss: 0.4442\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4196 - val_loss: 0.4441\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4195 - val_loss: 0.4467\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4199 - val_loss: 0.4453\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4191 - val_loss: 0.4422\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4189 - val_loss: 0.4459\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4194 - val_loss: 0.4468\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4189 - val_loss: 0.4430\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4188 - val_loss: 0.4451\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4190 - val_loss: 0.4441\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4189 - val_loss: 0.4444\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4189 - val_loss: 0.4430\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4187 - val_loss: 0.4457\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4185 - val_loss: 0.4434\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4187 - val_loss: 0.4451\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4184 - val_loss: 0.4433\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4184 - val_loss: 0.4434\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4183 - val_loss: 0.4438\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4183 - val_loss: 0.4442\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4180 - val_loss: 0.4450\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4182 - val_loss: 0.4440\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4180 - val_loss: 0.4446\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4178 - val_loss: 0.4427\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4178 - val_loss: 0.4441\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4181 - val_loss: 0.4438\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4180 - val_loss: 0.4440\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4180 - val_loss: 0.4440\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4179 - val_loss: 0.4443\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4177 - val_loss: 0.4433\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4178 - val_loss: 0.4435\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4178 - val_loss: 0.4429\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4178 - val_loss: 0.4445\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4177 - val_loss: 0.4437\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4176 - val_loss: 0.4432\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4177 - val_loss: 0.4438\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4178 - val_loss: 0.4435\n",
      "469/469 [==============================] - 1s 1ms/step\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.141\n",
      "Model:                            OLS   Adj. R-squared:                  0.141\n",
      "Method:                 Least Squares   F-statistic:                     410.2\n",
      "Date:                Sun, 19 May 2024   Prob (F-statistic):               0.00\n",
      "Time:                        03:33:42   Log-Likelihood:                -15553.\n",
      "No. Observations:               14998   AIC:                         3.112e+04\n",
      "Df Residuals:                   14991   BIC:                         3.117e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0950      0.006     16.980      0.000       0.084       0.106\n",
      "Mkt-RF         0.1620      0.006     27.029      0.000       0.150       0.174\n",
      "SMB            0.0867      0.011      7.945      0.000       0.065       0.108\n",
      "HML            0.1878      0.013     14.942      0.000       0.163       0.212\n",
      "RMW            0.1302      0.015      8.658      0.000       0.101       0.160\n",
      "CMA            0.1382      0.019      7.156      0.000       0.100       0.176\n",
      "MOM            0.3216      0.008     41.150      0.000       0.306       0.337\n",
      "==============================================================================\n",
      "Omnibus:                     3648.074   Durbin-Watson:                   2.018\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           188624.493\n",
      "Skew:                          -0.292   Prob(JB):                         0.00\n",
      "Kurtosis:                      20.364   Cond. No.                         4.01\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(           0      1      2      3      4      5\n",
       " 0       True  False  False  False  False  False\n",
       " 1      False  False  False  False  False   True\n",
       " 2      False  False  False  False  False   True\n",
       " 3       True  False  False  False  False  False\n",
       " 4      False  False  False  False   True  False\n",
       " ...      ...    ...    ...    ...    ...    ...\n",
       " 14993  False  False  False  False  False   True\n",
       " 14994  False  False   True  False  False  False\n",
       " 14995   True  False  False  False  False  False\n",
       " 14996   True  False  False  False  False  False\n",
       " 14997  False  False  False  False  False   True\n",
       " \n",
       " [14998 rows x 6 columns],\n",
       " 0        0.79\n",
       " 1        0.41\n",
       " 2        0.07\n",
       " 3       -0.63\n",
       " 4       -0.01\n",
       "          ... \n",
       " 14993    0.14\n",
       " 14994    0.01\n",
       " 14995    0.36\n",
       " 14996   -1.38\n",
       " 14997   -0.70\n",
       " Length: 14998, dtype: float64,\n",
       " <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x7b0106446ef0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define linear feed-forward neural net based on model_feed_forward\n",
    "def model_feed_forward_linear(X, y, X_train, y_train, X_val, y_val):\n",
    "    # Define the neural network model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='linear', input_shape=(X.shape[1],)))\n",
    "    model.add(Dense(16, activation='linear'))\n",
    "    model.add(Dense(6, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # Train the model, verbose = 0 means reports aren't printed\n",
    "    # at the end of each epoch\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=50,\n",
    "              validation_data=(X_val, y_val))\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(X)\n",
    "\n",
    "    pred_df = pd.DataFrame(predictions)\n",
    "\n",
    "    return predictions_to_returns(pred_df, y)\n",
    "\n",
    "# Calculate returns and alphas from linear neural net\n",
    "fitting_returns_data(\n",
    "    'ff6_factors_19630701_20230131.csv',\n",
    "    io_day_1_lag,\n",
    "    model_feed_forward_linear,\n",
    "    seed = COMMON_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XzogcR_otKvx",
   "metadata": {
    "id": "XzogcR_otKvx"
   },
   "source": [
    "The ReLU alpha of 0.1232 is higher than the linear alpha of 0.0950, while both are statistically significant at the 1% level. This indicates that the ReLU activation function better supports neural networks to identify profitable relationships between factors, though we may need more in-depth experiments to conclude this convincingly.\n",
    "\n",
    "### 1aii [10 points] Compare with linear model\n",
    "\n",
    "The following code defines a function called `model_linear_fit`, which fits a linear model on y_train and X_train and outputs the predicted return given `X`, called `pred_df`. The function then calculates the  returns of the linear model by running `predictions_to_returns(pred_df, y)`.\n",
    "\n",
    "Since the neural net is only fitting on linear relationships, we should see similar results across the linear neural net and the linear OLS model here.\n",
    "\n",
    "Calculate reults for the linear model below. How does the alpha compare to the linear neural net?  \n",
    "\n",
    "### Solution 1aii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d97083",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09d97083",
    "outputId": "3f56ad57-f39e-45db-a221-b71b933066a0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.127\n",
      "Model:                            OLS   Adj. R-squared:                  0.127\n",
      "Method:                 Least Squares   F-statistic:                     363.2\n",
      "Date:                Sun, 19 May 2024   Prob (F-statistic):               0.00\n",
      "Time:                        03:33:44   Log-Likelihood:                -15513.\n",
      "No. Observations:               14998   AIC:                         3.104e+04\n",
      "Df Residuals:                   14991   BIC:                         3.109e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0904      0.006     16.202      0.000       0.079       0.101\n",
      "Mkt-RF         0.1371      0.006     22.937      0.000       0.125       0.149\n",
      "SMB            0.1647      0.011     15.134      0.000       0.143       0.186\n",
      "HML            0.2111      0.013     16.842      0.000       0.187       0.236\n",
      "RMW            0.1475      0.015      9.833      0.000       0.118       0.177\n",
      "CMA            0.1534      0.019      7.967      0.000       0.116       0.191\n",
      "MOM            0.2758      0.008     35.382      0.000       0.261       0.291\n",
      "==============================================================================\n",
      "Omnibus:                     3960.117   Durbin-Watson:                   2.005\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           262916.099\n",
      "Skew:                          -0.336   Prob(JB):                         0.00\n",
      "Kurtosis:                      23.501   Cond. No.                         4.01\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(           0      1      2      3      4      5\n",
       " 0       True  False  False  False  False  False\n",
       " 1      False  False  False  False  False   True\n",
       " 2      False  False  False  False  False   True\n",
       " 3      False   True  False  False  False  False\n",
       " 4      False  False  False  False   True  False\n",
       " ...      ...    ...    ...    ...    ...    ...\n",
       " 14993  False  False  False  False  False   True\n",
       " 14994  False  False   True  False  False  False\n",
       " 14995   True  False  False  False  False  False\n",
       " 14996   True  False  False  False  False  False\n",
       " 14997  False  False  False  False  False   True\n",
       " \n",
       " [14998 rows x 6 columns],\n",
       " 0        0.79\n",
       " 1        0.41\n",
       " 2        0.07\n",
       " 3        0.07\n",
       " 4       -0.01\n",
       "          ... \n",
       " 14993    0.14\n",
       " 14994    0.01\n",
       " 14995    0.36\n",
       " 14996   -1.38\n",
       " 14997   -0.70\n",
       " Length: 14998, dtype: float64,\n",
       " <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x7b0109f955a0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define linear OLS model\n",
    "## Linear Model Fit\n",
    "def model_linear_fit(X, y, X_train, y_train, X_val, y_val):\n",
    "    model_OLS = sm.OLS(y_train, X_train).fit()\n",
    "    # Make predictions\n",
    "    predictions = model_OLS.predict(X)\n",
    "\n",
    "    pred_df = pd.DataFrame(predictions)\n",
    "\n",
    "    return predictions_to_returns(pred_df, y)\n",
    "\n",
    "# Calculate returns and alphas using linear OLS model\n",
    "fitting_returns_data(\n",
    "    'ff6_factors_19630701_20230131.csv',\n",
    "    io_day_1_lag,\n",
    "    model_linear_fit,\n",
    "    seed = COMMON_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746c7ff9",
   "metadata": {
    "id": "746c7ff9"
   },
   "source": [
    "The linear model alpha of 0.0904 is very similar the neural network model alpha of 0.0950, which is as expected. Both are statistically significant at the 1% level.\n",
    "\n",
    "### 1b [20 points] Include Interaction Terms\n",
    "Linear models don't account for any interaction effects. In order to account for an interaction we can add input variables that give the product of factor returns on each day. This would be analogous to adding a interaction term to a linear model.\n",
    "\n",
    "Using the io_ function `io_day_1_lag_second_order_input`, and your `model_linear_fit` function, calculate returns while including second order inputs.\n",
    "\n",
    "Write a new io_ function `io_day_lag_third_order_input`, to also include third order fits in your input data.\n",
    "\n",
    "How do these models compare to the ReLU alpha?\n",
    "\n",
    "\n",
    "### Solution 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e2921ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e2921ed",
    "outputId": "1b3704be-189e-452b-ced3-82585affe7c0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.164\n",
      "Model:                            OLS   Adj. R-squared:                  0.163\n",
      "Method:                 Least Squares   F-statistic:                     489.2\n",
      "Date:                Sun, 19 May 2024   Prob (F-statistic):               0.00\n",
      "Time:                        03:33:49   Log-Likelihood:                -16116.\n",
      "No. Observations:               14998   AIC:                         3.225e+04\n",
      "Df Residuals:                   14991   BIC:                         3.230e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0965      0.006     16.615      0.000       0.085       0.108\n",
      "Mkt-RF         0.2727      0.006     43.824      0.000       0.261       0.285\n",
      "SMB            0.1154      0.011     10.188      0.000       0.093       0.138\n",
      "HML            0.2557      0.013     19.601      0.000       0.230       0.281\n",
      "RMW            0.1325      0.016      8.485      0.000       0.102       0.163\n",
      "CMA            0.1257      0.020      6.270      0.000       0.086       0.165\n",
      "MOM            0.2588      0.008     31.892      0.000       0.243       0.275\n",
      "==============================================================================\n",
      "Omnibus:                     3804.967   Durbin-Watson:                   2.039\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           304893.099\n",
      "Skew:                          -0.010   Prob(JB):                         0.00\n",
      "Kurtosis:                      25.088   Cond. No.                         4.01\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(           0      1      2      3      4      5\n",
       " 0       True  False  False  False  False  False\n",
       " 1      False  False  False  False  False   True\n",
       " 2      False  False  False  False  False   True\n",
       " 3       True  False  False  False  False  False\n",
       " 4      False  False  False  False   True  False\n",
       " ...      ...    ...    ...    ...    ...    ...\n",
       " 14993  False  False  False  False  False   True\n",
       " 14994  False  False   True  False  False  False\n",
       " 14995   True  False  False  False  False  False\n",
       " 14996   True  False  False  False  False  False\n",
       " 14997  False  False  False  False  False   True\n",
       " \n",
       " [14998 rows x 6 columns],\n",
       " 0        0.79\n",
       " 1        0.41\n",
       " 2        0.07\n",
       " 3       -0.63\n",
       " 4       -0.01\n",
       "          ... \n",
       " 14993    0.14\n",
       " 14994    0.01\n",
       " 14995    0.36\n",
       " 14996   -1.38\n",
       " 14997   -0.70\n",
       " Length: 14998, dtype: float64,\n",
       " <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x7b0109f95ba0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate returns and alphas using linear OLS model\n",
    "fitting_returns_data(\n",
    "    'ff6_factors_19630701_20230131.csv',\n",
    "    io_day_1_lag_second_order_input,\n",
    "    model_linear_fit,\n",
    "    seed = COMMON_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd49b62a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd49b62a",
    "outputId": "d9995bcb-0f62-4d31-acf7-c50a85f21fc5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.120\n",
      "Model:                            OLS   Adj. R-squared:                  0.120\n",
      "Method:                 Least Squares   F-statistic:                     340.7\n",
      "Date:                Sun, 19 May 2024   Prob (F-statistic):               0.00\n",
      "Time:                        03:33:53   Log-Likelihood:                -16045.\n",
      "No. Observations:               14998   AIC:                         3.210e+04\n",
      "Df Residuals:                   14991   BIC:                         3.216e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1240      0.006     21.447      0.000       0.113       0.135\n",
      "Mkt-RF         0.1922      0.006     31.031      0.000       0.180       0.204\n",
      "SMB            0.0399      0.011      3.536      0.000       0.018       0.062\n",
      "HML            0.1763      0.013     13.579      0.000       0.151       0.202\n",
      "RMW            0.1619      0.016     10.419      0.000       0.131       0.192\n",
      "CMA            0.0831      0.020      4.165      0.000       0.044       0.122\n",
      "MOM            0.2760      0.008     34.172      0.000       0.260       0.292\n",
      "==============================================================================\n",
      "Omnibus:                     4135.930   Durbin-Watson:                   1.884\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           268573.934\n",
      "Skew:                           0.431   Prob(JB):                         0.00\n",
      "Kurtosis:                      23.713   Cond. No.                         4.01\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(           0      1      2      3      4      5\n",
       " 0      False  False  False  False   True  False\n",
       " 1      False  False  False  False  False   True\n",
       " 2      False  False  False  False  False   True\n",
       " 3       True  False  False  False  False  False\n",
       " 4      False  False  False  False   True  False\n",
       " ...      ...    ...    ...    ...    ...    ...\n",
       " 14993  False  False  False  False  False   True\n",
       " 14994  False  False   True  False  False  False\n",
       " 14995  False   True  False  False  False  False\n",
       " 14996  False   True  False  False  False  False\n",
       " 14997  False  False  False  False  False   True\n",
       " \n",
       " [14998 rows x 6 columns],\n",
       " 0       -0.21\n",
       " 1        0.41\n",
       " 2        0.07\n",
       " 3       -0.63\n",
       " 4       -0.01\n",
       "          ... \n",
       " 14993    0.14\n",
       " 14994    0.01\n",
       " 14995    0.32\n",
       " 14996    0.05\n",
       " 14997   -0.70\n",
       " Length: 14998, dtype: float64,\n",
       " <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x7b0109f95390>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create input output pairs where input data includes second order interactions\n",
    "\n",
    "# This is actually third order as described in the question. The outputs are not\n",
    "# similar to the sanity checks that professor Sinclair wrote for us.\n",
    "# def io_day_lag_third_order_input(data):\n",
    "#     X, y = io_day_1_lag(data)\n",
    "#     cols = X.columns\n",
    "\n",
    "#     X, y = io_day_1_lag_second_order_input(data)\n",
    "\n",
    "#     for i in range(len(cols)):\n",
    "#         for j in range(i+1, len(cols)):\n",
    "#           for k in range(j+1, len(cols)):\n",
    "#             col_name = cols[i] + cols[j] + cols[k]\n",
    "#             col_values = X[cols[i]] * X[cols[j]] * X[cols[k]]\n",
    "#             X[col_name] = col_values\n",
    "\n",
    "#     return X, y\n",
    "\n",
    "# This is fourth order. The outputs agree very closely with professor Sinclair's\n",
    "# sanity checks.\n",
    "def io_day_lag_third_order_input(data):\n",
    "    # Create input output pairs where input data includes second order interactions\n",
    "    X, y = io_day_1_lag_second_order_input(data)\n",
    "    cols = X.columns\n",
    "\n",
    "    for i in range(len(cols)):\n",
    "        for j in range(i+1, len(cols)):\n",
    "            col_name = cols[i] + cols[j]\n",
    "            col_values = X[cols[i]] * X[cols[j]]\n",
    "            X[col_name] = col_values\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Calculate returns and alphas using third order interactions\n",
    "fitting_returns_data(\n",
    "    'ff6_factors_19630701_20230131.csv',\n",
    "    io_day_lag_third_order_input,\n",
    "    model_linear_fit,\n",
    "    seed = COMMON_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c46887",
   "metadata": {
    "id": "b1c46887"
   },
   "source": [
    "The second order linear model has an alpha of 0.0965, which is lower than the ReLU alpha of 0.1232, but is significant at the 1% level. On the other hand, the third order linear model that we implemented as fourth order to be similar to the desired output has alpha of 0.1240, which is very similar to the ReLU alpha. It is also statistically significant at the 1% level.\n",
    "\n",
    "## Question 2 - Adding Time Lag Parameters\n",
    "### 2 [25 points] Lag Time Parameters\n",
    "Our current neural net only uses the past 1 day of data. For time series data, including more lag days can be useful. For example, if a factor return is high for 2 consecutive days, that may be more informative than just knowing that the return was only high for the previous day.\n",
    "\n",
    "In this question, we will simply add a new column to our input data for each lagged data. This is analogous to an AutoRegressive Model, which is a popular financial engineering tool, [see this textbook](https://link.springer.com/book/10.1007/978-1-4939-2614-5). In the Neural Net literature, a Recurrent Neural Net is a common tool for more directly accounting for time lagged data directly in the neural net architecture, but the lagged model gets us a good amount of the way there!\n",
    "\n",
    "Starting from the `io_day_1_lag` function write an `io_day_5_lag` function, which adds to the input dataframe 5 days of lagged data per factor. This will mean your input data will now have 6*5 = 30 columns instead of 6 columns.\n",
    "\n",
    "When complete, run the following and compare results to the original ReLU model from Question 0. How do the results compare? Should we continue to to pursue incorporating lag effects in our analysis of this data?\n",
    "\n",
    "```\n",
    "fitting_returns_data(\n",
    "    'ff6_factors_19630701_20230131.csv',\n",
    "    io_day_5_lag,\n",
    "    model_feed_forward);\n",
    " ```\n",
    "\n",
    " ### Question 2 Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ab4fd43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ab4fd43",
    "outputId": "178092e2-c063-4d0c-ef79-ad37fe64aaa8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4547 - val_loss: 0.4522\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4241 - val_loss: 0.4499\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4196 - val_loss: 0.4489\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4159 - val_loss: 0.4481\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4123 - val_loss: 0.4488\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4085 - val_loss: 0.4482\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4051 - val_loss: 0.4479\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4017 - val_loss: 0.4482\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3992 - val_loss: 0.4505\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3956 - val_loss: 0.4498\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3931 - val_loss: 0.4540\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3903 - val_loss: 0.4548\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3883 - val_loss: 0.4583\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3858 - val_loss: 0.4586\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3833 - val_loss: 0.4583\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3816 - val_loss: 0.4601\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3795 - val_loss: 0.4622\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3775 - val_loss: 0.4631\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3750 - val_loss: 0.4630\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3727 - val_loss: 0.4625\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3709 - val_loss: 0.4664\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3696 - val_loss: 0.4667\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3672 - val_loss: 0.4704\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3664 - val_loss: 0.4656\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3646 - val_loss: 0.4686\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3629 - val_loss: 0.4725\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3614 - val_loss: 0.4721\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3605 - val_loss: 0.4719\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3591 - val_loss: 0.4699\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3580 - val_loss: 0.4756\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3567 - val_loss: 0.4749\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3555 - val_loss: 0.4768\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3544 - val_loss: 0.4743\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3534 - val_loss: 0.4767\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3519 - val_loss: 0.4768\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3510 - val_loss: 0.4765\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3501 - val_loss: 0.4786\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3495 - val_loss: 0.4818\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3475 - val_loss: 0.4800\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3463 - val_loss: 0.4844\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3463 - val_loss: 0.4818\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3453 - val_loss: 0.4808\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3439 - val_loss: 0.4903\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3438 - val_loss: 0.4897\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.4884\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3428 - val_loss: 0.4884\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3419 - val_loss: 0.4907\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3410 - val_loss: 0.4896\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3401 - val_loss: 0.4939\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3396 - val_loss: 0.4891\n",
      "469/469 [==============================] - 1s 1ms/step\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.292\n",
      "Model:                            OLS   Adj. R-squared:                  0.292\n",
      "Method:                 Least Squares   F-statistic:                     1031.\n",
      "Date:                Sun, 19 May 2024   Prob (F-statistic):               0.00\n",
      "Time:                        03:34:42   Log-Likelihood:                -16382.\n",
      "No. Observations:               14994   AIC:                         3.278e+04\n",
      "Df Residuals:                   14987   BIC:                         3.283e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1574      0.006     26.605      0.000       0.146       0.169\n",
      "Mkt-RF         0.4712      0.006     74.362      0.000       0.459       0.484\n",
      "SMB           -0.0452      0.012     -3.916      0.000      -0.068      -0.023\n",
      "HML            0.1372      0.013     10.330      0.000       0.111       0.163\n",
      "RMW            0.0766      0.016      4.817      0.000       0.045       0.108\n",
      "CMA            0.0696      0.020      3.407      0.001       0.030       0.110\n",
      "MOM            0.1695      0.008     20.519      0.000       0.153       0.186\n",
      "==============================================================================\n",
      "Omnibus:                     7028.886   Durbin-Watson:                   1.714\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           145900.245\n",
      "Skew:                           1.764   Prob(JB):                         0.00\n",
      "Kurtosis:                      17.869   Cond. No.                         4.01\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(           0      1      2      3      4      5\n",
       " 0       True  False  False  False  False  False\n",
       " 1      False  False  False  False  False   True\n",
       " 2       True  False  False  False  False  False\n",
       " 3       True  False  False  False  False  False\n",
       " 4       True  False  False  False  False  False\n",
       " ...      ...    ...    ...    ...    ...    ...\n",
       " 14989  False  False   True  False  False  False\n",
       " 14990  False  False  False  False  False   True\n",
       " 14991   True  False  False  False  False  False\n",
       " 14992   True  False  False  False  False  False\n",
       " 14993  False  False  False  False  False   True\n",
       " \n",
       " [14994 rows x 6 columns],\n",
       " 0        0.45\n",
       " 1        0.16\n",
       " 2       -0.16\n",
       " 3       -0.12\n",
       " 4       -0.62\n",
       "          ... \n",
       " 14989    0.65\n",
       " 14990   -1.23\n",
       " 14991    0.36\n",
       " 14992   -1.38\n",
       " 14993   -0.70\n",
       " Length: 14994, dtype: float64,\n",
       " <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x7b01060fe170>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def io_day_5_lag(data):\n",
    "    X = data.shift(1).add_suffix('_lag1')\n",
    "    for i in range(2, 6):\n",
    "        shifted_data = data.shift(i).add_suffix('_lag{}'.format(i))\n",
    "        X = pd.concat([X, shifted_data], axis=1)\n",
    "    X = X.dropna().reset_index(drop=True)\n",
    "    y = data.iloc[5:,:].reset_index(drop=True)\n",
    "    return X, y\n",
    "\n",
    "# Calculate returns and alphas using the feed forward neural net with\n",
    "# five day lagged input variables.\n",
    "fitting_returns_data(\n",
    "    'ff6_factors_19630701_20230131.csv',\n",
    "    io_day_5_lag,\n",
    "    model_feed_forward,\n",
    "    seed = COMMON_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c84cfba",
   "metadata": {
    "id": "3c84cfba"
   },
   "source": [
    "The 5 day lag feed-forward neural network model has an alpha of 0.1574, which is larger than the 1 day lag ReLU model alpha of 0.1232 and statistically significant at the 1% level. This indicates that we should continue to incorporate lag effects into our models, and supports the intuitive notion that giving the model factor information from days earlier than the previous day will improve the performance.\n",
    "\n",
    "## Question 3 - Investigating Potentials for P-Hacking\n",
    "### 3 [25 points] Randomness in Alphas\n",
    "\n",
    "Neural  nets are fit via a Stochastic Gradient Descent. This implies that there is inherent randomness in any fit of the model. One good way to account for this noise in your model is to refit the model multiple times and observe the distribution. It's more accurate to report the median or mean of these estimates, although it can be hard to tell if a paper/report has cherry-picked the best result in this way.\n",
    "\n",
    "Using the `io_day_1_lag`, and `model_feed_forward` settings, rerun the model 100 times and get a distribution for the alpha given. (You can use the `seed` parameter in the `fitting_returns_data` function if you want to be able to reproduce a given high return.)\n",
    "\n",
    "Set `print_summary = False` in `fitting_returns_data` in order to avoid large amounts of output.\n",
    "\n",
    "What's the highest return you could get if you were to ignore the importance of the robustness of a model result? What would be a downside of reporting a result like this?\n",
    "\n",
    "Note: running the model 100 times may take awhile (over an hour on Google Colab). Debug your code before attempting the 100 cycles.\n",
    "\n",
    "### Question 3 Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7000f3c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7000f3c5",
    "outputId": "4fbe5e39-6129-4396-ebe2-3eca0d923791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4060 - val_loss: 0.4426\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4059 - val_loss: 0.4442\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4055 - val_loss: 0.4429\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4054 - val_loss: 0.4430\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4050 - val_loss: 0.4445\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4049 - val_loss: 0.4428\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4441\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4047 - val_loss: 0.4440\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4037 - val_loss: 0.4435\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4041 - val_loss: 0.4429\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4030 - val_loss: 0.4439\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4031 - val_loss: 0.4449\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4032 - val_loss: 0.4440\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4027 - val_loss: 0.4440\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4024 - val_loss: 0.4457\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4022 - val_loss: 0.4454\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4019 - val_loss: 0.4475\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4016 - val_loss: 0.4450\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4010 - val_loss: 0.4446\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4008 - val_loss: 0.4462\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4010 - val_loss: 0.4451\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4006 - val_loss: 0.4449\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "50\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4269 - val_loss: 0.4482\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4196 - val_loss: 0.4461\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4170 - val_loss: 0.4456\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4150 - val_loss: 0.4459\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4135 - val_loss: 0.4454\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4132 - val_loss: 0.4448\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4122 - val_loss: 0.4450\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4443\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4445\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4104 - val_loss: 0.4447\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4097 - val_loss: 0.4447\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4094 - val_loss: 0.4449\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4089 - val_loss: 0.4443\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4083 - val_loss: 0.4450\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4078 - val_loss: 0.4449\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4078 - val_loss: 0.4448\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4073 - val_loss: 0.4449\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4067 - val_loss: 0.4459\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4067 - val_loss: 0.4458\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4461\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4458\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4053 - val_loss: 0.4452\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4051 - val_loss: 0.4452\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4047 - val_loss: 0.4446\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4044 - val_loss: 0.4464\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4459\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4037 - val_loss: 0.4466\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4034 - val_loss: 0.4461\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4032 - val_loss: 0.4459\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4030 - val_loss: 0.4460\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4030 - val_loss: 0.4459\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4022 - val_loss: 0.4449\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4023 - val_loss: 0.4468\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4021 - val_loss: 0.4458\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4016 - val_loss: 0.4481\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4014 - val_loss: 0.4471\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4013 - val_loss: 0.4458\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4012 - val_loss: 0.4471\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4005 - val_loss: 0.4481\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4004 - val_loss: 0.4454\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4005 - val_loss: 0.4462\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4000 - val_loss: 0.4490\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4001 - val_loss: 0.4473\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3997 - val_loss: 0.4496\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3996 - val_loss: 0.4475\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3989 - val_loss: 0.4477\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3986 - val_loss: 0.4477\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3985 - val_loss: 0.4487\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3980 - val_loss: 0.4496\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3982 - val_loss: 0.4492\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4222 - val_loss: 0.4732\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4144 - val_loss: 0.4705\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4120 - val_loss: 0.4685\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4104 - val_loss: 0.4676\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4093 - val_loss: 0.4684\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4082 - val_loss: 0.4689\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4079 - val_loss: 0.4666\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4073 - val_loss: 0.4671\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.4653\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4057 - val_loss: 0.4661\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4050 - val_loss: 0.4654\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4045 - val_loss: 0.4668\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4038 - val_loss: 0.4674\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4035 - val_loss: 0.4662\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.4676\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4024 - val_loss: 0.4647\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4021 - val_loss: 0.4659\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4017 - val_loss: 0.4655\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4011 - val_loss: 0.4669\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4006 - val_loss: 0.4699\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4005 - val_loss: 0.4656\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4004 - val_loss: 0.4648\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3997 - val_loss: 0.4670\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3996 - val_loss: 0.4669\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3995 - val_loss: 0.4673\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3990 - val_loss: 0.4676\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3987 - val_loss: 0.4689\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3986 - val_loss: 0.4667\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3983 - val_loss: 0.4692\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3981 - val_loss: 0.4662\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3976 - val_loss: 0.4685\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3977 - val_loss: 0.4676\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3975 - val_loss: 0.4672\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3971 - val_loss: 0.4676\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3968 - val_loss: 0.4665\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3964 - val_loss: 0.4697\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3963 - val_loss: 0.4718\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3963 - val_loss: 0.4664\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3961 - val_loss: 0.4693\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3956 - val_loss: 0.4674\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3954 - val_loss: 0.4687\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3952 - val_loss: 0.4676\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3949 - val_loss: 0.4707\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3951 - val_loss: 0.4669\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3946 - val_loss: 0.4706\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3946 - val_loss: 0.4689\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3942 - val_loss: 0.4698\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3942 - val_loss: 0.4696\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3940 - val_loss: 0.4704\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3938 - val_loss: 0.4705\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4319 - val_loss: 0.4364\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4230 - val_loss: 0.4340\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4204 - val_loss: 0.4322\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4184 - val_loss: 0.4316\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4171 - val_loss: 0.4306\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4159 - val_loss: 0.4302\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4149 - val_loss: 0.4297\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4141 - val_loss: 0.4304\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4133 - val_loss: 0.4306\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4127 - val_loss: 0.4303\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4120 - val_loss: 0.4302\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4118 - val_loss: 0.4295\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4112 - val_loss: 0.4302\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4301\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4104 - val_loss: 0.4309\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4099 - val_loss: 0.4306\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4095 - val_loss: 0.4298\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4094 - val_loss: 0.4307\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4091 - val_loss: 0.4304\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4084 - val_loss: 0.4309\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4082 - val_loss: 0.4328\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4083 - val_loss: 0.4312\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4074 - val_loss: 0.4304\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4072 - val_loss: 0.4313\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4074 - val_loss: 0.4308\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4065 - val_loss: 0.4316\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4062 - val_loss: 0.4320\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4059 - val_loss: 0.4342\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4057 - val_loss: 0.4311\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4055 - val_loss: 0.4346\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4050 - val_loss: 0.4315\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4048 - val_loss: 0.4347\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4049 - val_loss: 0.4333\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4044 - val_loss: 0.4359\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4039 - val_loss: 0.4338\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4038 - val_loss: 0.4342\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4033 - val_loss: 0.4361\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4031 - val_loss: 0.4357\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4034 - val_loss: 0.4337\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.4337\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4024 - val_loss: 0.4330\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4023 - val_loss: 0.4346\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4022 - val_loss: 0.4366\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4021 - val_loss: 0.4343\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4016 - val_loss: 0.4360\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4011 - val_loss: 0.4377\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4010 - val_loss: 0.4346\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4010 - val_loss: 0.4389\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4006 - val_loss: 0.4362\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4005 - val_loss: 0.4389\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4315 - val_loss: 0.4270\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4245 - val_loss: 0.4238\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4221 - val_loss: 0.4241\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4205 - val_loss: 0.4236\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4192 - val_loss: 0.4241\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4184 - val_loss: 0.4228\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4181 - val_loss: 0.4228\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4168 - val_loss: 0.4225\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4163 - val_loss: 0.4233\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4156 - val_loss: 0.4217\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4149 - val_loss: 0.4224\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4149 - val_loss: 0.4217\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4144 - val_loss: 0.4211\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4136 - val_loss: 0.4225\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4135 - val_loss: 0.4209\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4130 - val_loss: 0.4210\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4128 - val_loss: 0.4211\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4122 - val_loss: 0.4215\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4120 - val_loss: 0.4218\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4116 - val_loss: 0.4212\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4111 - val_loss: 0.4210\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4222\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4102 - val_loss: 0.4209\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4100 - val_loss: 0.4215\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4100 - val_loss: 0.4212\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4095 - val_loss: 0.4205\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4094 - val_loss: 0.4198\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4089 - val_loss: 0.4200\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4086 - val_loss: 0.4210\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4086 - val_loss: 0.4207\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4211\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.4216\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4073 - val_loss: 0.4196\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4072 - val_loss: 0.4208\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.4217\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4071 - val_loss: 0.4218\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4061 - val_loss: 0.4221\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4064 - val_loss: 0.4215\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4061 - val_loss: 0.4242\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4059 - val_loss: 0.4216\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4055 - val_loss: 0.4215\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4050 - val_loss: 0.4229\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4052 - val_loss: 0.4220\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4049 - val_loss: 0.4221\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4046 - val_loss: 0.4225\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4232\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4045 - val_loss: 0.4223\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4035 - val_loss: 0.4235\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4037 - val_loss: 0.4243\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4036 - val_loss: 0.4235\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 4ms/step - loss: 0.4384 - val_loss: 0.4020\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4308 - val_loss: 0.4006\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4283 - val_loss: 0.3979\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4265 - val_loss: 0.3971\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4254 - val_loss: 0.3968\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4245 - val_loss: 0.3968\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4240 - val_loss: 0.3969\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4230 - val_loss: 0.3975\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4228 - val_loss: 0.3970\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4222 - val_loss: 0.3972\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4217 - val_loss: 0.3969\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4208 - val_loss: 0.3975\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4206 - val_loss: 0.3980\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4203 - val_loss: 0.3977\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4196 - val_loss: 0.3981\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4191 - val_loss: 0.3977\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4188 - val_loss: 0.3982\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4185 - val_loss: 0.3985\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4181 - val_loss: 0.3988\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4177 - val_loss: 0.3989\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4174 - val_loss: 0.3978\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4168 - val_loss: 0.3989\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4167 - val_loss: 0.3978\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4167 - val_loss: 0.3982\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4158 - val_loss: 0.3993\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4158 - val_loss: 0.3994\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4154 - val_loss: 0.4004\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4155 - val_loss: 0.3982\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4153 - val_loss: 0.3991\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4145 - val_loss: 0.3987\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4146 - val_loss: 0.3991\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4144 - val_loss: 0.3995\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4140 - val_loss: 0.3981\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4138 - val_loss: 0.4003\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4134 - val_loss: 0.4010\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4134 - val_loss: 0.3999\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4130 - val_loss: 0.3998\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4128 - val_loss: 0.3989\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4127 - val_loss: 0.4021\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4126 - val_loss: 0.4005\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4122 - val_loss: 0.3995\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4123 - val_loss: 0.4008\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4119 - val_loss: 0.4011\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4003\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4116 - val_loss: 0.4027\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4110 - val_loss: 0.4012\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4116 - val_loss: 0.4018\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4107 - val_loss: 0.4023\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4113 - val_loss: 0.4005\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4107 - val_loss: 0.4013\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4289 - val_loss: 0.4437\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4199 - val_loss: 0.4421\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4173 - val_loss: 0.4411\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4159 - val_loss: 0.4414\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4149 - val_loss: 0.4408\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4144 - val_loss: 0.4413\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4133 - val_loss: 0.4407\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4125 - val_loss: 0.4398\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4119 - val_loss: 0.4411\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4113 - val_loss: 0.4403\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4109 - val_loss: 0.4396\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4103 - val_loss: 0.4403\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4096 - val_loss: 0.4388\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4092 - val_loss: 0.4393\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4088 - val_loss: 0.4390\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4083 - val_loss: 0.4391\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4078 - val_loss: 0.4395\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4077 - val_loss: 0.4385\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4074 - val_loss: 0.4372\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4069 - val_loss: 0.4380\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4064 - val_loss: 0.4397\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.4384\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4060 - val_loss: 0.4392\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4058 - val_loss: 0.4384\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4051 - val_loss: 0.4396\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4054 - val_loss: 0.4396\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4049 - val_loss: 0.4398\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4046 - val_loss: 0.4405\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4043 - val_loss: 0.4413\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4042 - val_loss: 0.4401\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4037 - val_loss: 0.4415\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4040 - val_loss: 0.4407\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4031 - val_loss: 0.4413\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4034 - val_loss: 0.4418\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4033 - val_loss: 0.4409\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4027 - val_loss: 0.4422\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4026 - val_loss: 0.4419\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4026 - val_loss: 0.4420\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4023 - val_loss: 0.4420\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4019 - val_loss: 0.4424\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4016 - val_loss: 0.4435\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4013 - val_loss: 0.4426\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4014 - val_loss: 0.4427\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4012 - val_loss: 0.4445\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4007 - val_loss: 0.4445\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4009 - val_loss: 0.4428\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4009 - val_loss: 0.4437\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4007 - val_loss: 0.4439\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4002 - val_loss: 0.4440\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4000 - val_loss: 0.4451\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4385 - val_loss: 0.4317\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4272 - val_loss: 0.4301\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4238 - val_loss: 0.4291\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4221 - val_loss: 0.4282\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4208 - val_loss: 0.4271\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4192 - val_loss: 0.4274\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4181 - val_loss: 0.4272\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4176 - val_loss: 0.4268\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4171 - val_loss: 0.4273\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4162 - val_loss: 0.4271\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4156 - val_loss: 0.4272\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4152 - val_loss: 0.4271\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4144 - val_loss: 0.4274\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4144 - val_loss: 0.4273\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4142 - val_loss: 0.4268\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4134 - val_loss: 0.4271\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4128 - val_loss: 0.4271\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4124 - val_loss: 0.4270\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4119 - val_loss: 0.4284\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4113 - val_loss: 0.4291\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4113 - val_loss: 0.4287\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4109 - val_loss: 0.4288\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4102 - val_loss: 0.4285\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4099 - val_loss: 0.4284\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4097 - val_loss: 0.4286\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4095 - val_loss: 0.4289\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4092 - val_loss: 0.4293\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4087 - val_loss: 0.4299\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4085 - val_loss: 0.4292\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4082 - val_loss: 0.4295\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4077 - val_loss: 0.4303\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4077 - val_loss: 0.4299\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4072 - val_loss: 0.4308\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4070 - val_loss: 0.4307\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4067 - val_loss: 0.4314\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4062 - val_loss: 0.4318\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4066 - val_loss: 0.4317\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4057 - val_loss: 0.4312\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4054 - val_loss: 0.4307\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4056 - val_loss: 0.4306\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4049 - val_loss: 0.4317\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4045 - val_loss: 0.4325\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4045 - val_loss: 0.4336\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4042 - val_loss: 0.4309\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4040 - val_loss: 0.4316\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4034 - val_loss: 0.4322\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4032 - val_loss: 0.4324\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4034 - val_loss: 0.4332\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4025 - val_loss: 0.4327\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4025 - val_loss: 0.4339\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4346 - val_loss: 0.4252\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4246 - val_loss: 0.4226\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4216 - val_loss: 0.4220\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4203 - val_loss: 0.4214\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4192 - val_loss: 0.4213\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4180 - val_loss: 0.4211\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4175 - val_loss: 0.4209\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4168 - val_loss: 0.4218\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4162 - val_loss: 0.4215\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4156 - val_loss: 0.4223\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4145 - val_loss: 0.4219\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4147 - val_loss: 0.4230\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4142 - val_loss: 0.4222\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4137 - val_loss: 0.4230\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4127 - val_loss: 0.4235\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4131 - val_loss: 0.4234\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4123 - val_loss: 0.4238\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4241\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4237\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4235\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4108 - val_loss: 0.4245\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4107 - val_loss: 0.4235\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4099 - val_loss: 0.4242\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4096 - val_loss: 0.4243\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4091 - val_loss: 0.4252\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4091 - val_loss: 0.4250\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4087 - val_loss: 0.4258\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4084 - val_loss: 0.4262\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4252\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4078 - val_loss: 0.4264\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4071 - val_loss: 0.4259\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4068 - val_loss: 0.4258\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4066 - val_loss: 0.4263\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4060 - val_loss: 0.4260\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4272\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4060 - val_loss: 0.4288\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4055 - val_loss: 0.4279\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4051 - val_loss: 0.4286\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4047 - val_loss: 0.4295\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4043 - val_loss: 0.4282\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4039 - val_loss: 0.4287\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4286\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4038 - val_loss: 0.4281\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4036 - val_loss: 0.4290\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4032 - val_loss: 0.4280\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4031 - val_loss: 0.4293\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4027 - val_loss: 0.4289\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4026 - val_loss: 0.4298\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4022 - val_loss: 0.4289\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4019 - val_loss: 0.4289\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4417 - val_loss: 0.4246\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4280 - val_loss: 0.4211\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4248 - val_loss: 0.4195\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4223 - val_loss: 0.4175\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4209 - val_loss: 0.4174\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4194 - val_loss: 0.4168\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4188 - val_loss: 0.4164\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4178 - val_loss: 0.4168\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4173 - val_loss: 0.4160\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4164 - val_loss: 0.4160\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4159 - val_loss: 0.4155\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4152 - val_loss: 0.4155\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4147 - val_loss: 0.4152\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4140 - val_loss: 0.4167\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4136 - val_loss: 0.4153\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4131 - val_loss: 0.4158\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4123 - val_loss: 0.4157\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4124 - val_loss: 0.4162\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4171\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4166\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4170\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4103 - val_loss: 0.4177\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4094 - val_loss: 0.4171\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4092 - val_loss: 0.4183\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4089 - val_loss: 0.4176\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4085 - val_loss: 0.4183\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4080 - val_loss: 0.4179\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.4180\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4074 - val_loss: 0.4186\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4071 - val_loss: 0.4185\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4066 - val_loss: 0.4193\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.4186\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4056 - val_loss: 0.4197\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4054 - val_loss: 0.4189\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4056 - val_loss: 0.4193\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4053 - val_loss: 0.4186\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4049 - val_loss: 0.4201\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4043 - val_loss: 0.4201\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4042 - val_loss: 0.4194\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4039 - val_loss: 0.4199\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4033 - val_loss: 0.4206\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4038 - val_loss: 0.4198\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.4208\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4030 - val_loss: 0.4202\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4023 - val_loss: 0.4194\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4025 - val_loss: 0.4192\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4019 - val_loss: 0.4199\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4018 - val_loss: 0.4200\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4009 - val_loss: 0.4200\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4014 - val_loss: 0.4209\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 0.4263 - val_loss: 0.4484\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4179 - val_loss: 0.4470\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4155 - val_loss: 0.4470\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4141 - val_loss: 0.4465\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4132 - val_loss: 0.4471\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4123 - val_loss: 0.4460\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4114 - val_loss: 0.4468\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4110 - val_loss: 0.4464\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4103 - val_loss: 0.4462\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4098 - val_loss: 0.4462\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4091 - val_loss: 0.4475\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4086 - val_loss: 0.4462\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4086 - val_loss: 0.4470\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4079 - val_loss: 0.4472\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4075 - val_loss: 0.4472\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4070 - val_loss: 0.4473\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4069 - val_loss: 0.4460\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4061 - val_loss: 0.4485\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4061 - val_loss: 0.4465\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4470\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4053 - val_loss: 0.4473\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4049 - val_loss: 0.4488\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4048 - val_loss: 0.4488\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4047 - val_loss: 0.4479\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4044 - val_loss: 0.4475\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4038 - val_loss: 0.4480\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4037 - val_loss: 0.4466\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4032 - val_loss: 0.4500\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.4476\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4027 - val_loss: 0.4487\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4026 - val_loss: 0.4466\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4022 - val_loss: 0.4487\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4023 - val_loss: 0.4481\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4018 - val_loss: 0.4476\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4015 - val_loss: 0.4481\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4014 - val_loss: 0.4473\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4008 - val_loss: 0.4480\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4012 - val_loss: 0.4498\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4006 - val_loss: 0.4488\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4006 - val_loss: 0.4492\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4002 - val_loss: 0.4488\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4001 - val_loss: 0.4519\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4005 - val_loss: 0.4497\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3995 - val_loss: 0.4512\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3996 - val_loss: 0.4485\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3995 - val_loss: 0.4514\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3996 - val_loss: 0.4479\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3991 - val_loss: 0.4488\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3989 - val_loss: 0.4504\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3989 - val_loss: 0.4541\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "60\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4317 - val_loss: 0.4164\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4266 - val_loss: 0.4145\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4249 - val_loss: 0.4140\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4235 - val_loss: 0.4131\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4221 - val_loss: 0.4128\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4215 - val_loss: 0.4131\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4205 - val_loss: 0.4123\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4198 - val_loss: 0.4127\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4194 - val_loss: 0.4125\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4186 - val_loss: 0.4130\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4182 - val_loss: 0.4124\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4173 - val_loss: 0.4125\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4171 - val_loss: 0.4131\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4167 - val_loss: 0.4126\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4165 - val_loss: 0.4119\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4158 - val_loss: 0.4119\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4152 - val_loss: 0.4130\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4151 - val_loss: 0.4123\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4147 - val_loss: 0.4130\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4141 - val_loss: 0.4121\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4136 - val_loss: 0.4131\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4134 - val_loss: 0.4118\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4132 - val_loss: 0.4132\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4129 - val_loss: 0.4125\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4126 - val_loss: 0.4135\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4126 - val_loss: 0.4130\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4122 - val_loss: 0.4131\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4119 - val_loss: 0.4121\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4117 - val_loss: 0.4137\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4112 - val_loss: 0.4132\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4113 - val_loss: 0.4136\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4109 - val_loss: 0.4142\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4107 - val_loss: 0.4142\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4103 - val_loss: 0.4135\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4104 - val_loss: 0.4140\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4096 - val_loss: 0.4148\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4094 - val_loss: 0.4148\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4092 - val_loss: 0.4151\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4088 - val_loss: 0.4172\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4086 - val_loss: 0.4143\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4080 - val_loss: 0.4150\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4083 - val_loss: 0.4142\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4080 - val_loss: 0.4146\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4073 - val_loss: 0.4147\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.4158\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4068 - val_loss: 0.4147\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4066 - val_loss: 0.4165\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4066 - val_loss: 0.4173\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4065 - val_loss: 0.4163\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4169\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4299 - val_loss: 0.4451\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4214 - val_loss: 0.4440\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4190 - val_loss: 0.4432\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4174 - val_loss: 0.4445\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4162 - val_loss: 0.4438\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4149 - val_loss: 0.4448\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4138 - val_loss: 0.4453\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4130 - val_loss: 0.4450\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4124 - val_loss: 0.4448\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4118 - val_loss: 0.4456\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4111 - val_loss: 0.4457\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4104 - val_loss: 0.4455\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4103 - val_loss: 0.4465\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4095 - val_loss: 0.4457\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4087 - val_loss: 0.4461\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4085 - val_loss: 0.4468\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4082 - val_loss: 0.4460\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4076 - val_loss: 0.4463\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4073 - val_loss: 0.4473\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4065 - val_loss: 0.4477\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4062 - val_loss: 0.4476\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4057 - val_loss: 0.4482\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4055 - val_loss: 0.4481\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4050 - val_loss: 0.4482\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4046 - val_loss: 0.4486\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4043 - val_loss: 0.4487\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4502\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4037 - val_loss: 0.4506\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4033 - val_loss: 0.4490\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4031 - val_loss: 0.4516\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4025 - val_loss: 0.4513\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4029 - val_loss: 0.4514\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4021 - val_loss: 0.4556\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4022 - val_loss: 0.4529\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4014 - val_loss: 0.4522\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4014 - val_loss: 0.4500\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4011 - val_loss: 0.4529\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4008 - val_loss: 0.4513\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4004 - val_loss: 0.4508\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4000 - val_loss: 0.4512\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4004 - val_loss: 0.4527\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3995 - val_loss: 0.4549\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3996 - val_loss: 0.4520\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3995 - val_loss: 0.4526\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3988 - val_loss: 0.4527\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3991 - val_loss: 0.4532\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3985 - val_loss: 0.4513\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3985 - val_loss: 0.4542\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3982 - val_loss: 0.4537\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3984 - val_loss: 0.4538\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4293 - val_loss: 0.4425\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4203 - val_loss: 0.4397\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4176 - val_loss: 0.4392\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4159 - val_loss: 0.4384\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4147 - val_loss: 0.4387\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4138 - val_loss: 0.4387\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4127 - val_loss: 0.4387\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4122 - val_loss: 0.4389\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4115 - val_loss: 0.4383\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4106 - val_loss: 0.4392\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4102 - val_loss: 0.4394\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4099 - val_loss: 0.4388\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4092 - val_loss: 0.4387\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4086 - val_loss: 0.4386\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4085 - val_loss: 0.4393\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4382\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4073 - val_loss: 0.4390\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4069 - val_loss: 0.4391\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4067 - val_loss: 0.4398\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4061 - val_loss: 0.4397\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4059 - val_loss: 0.4394\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4052 - val_loss: 0.4400\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4048 - val_loss: 0.4396\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4042 - val_loss: 0.4400\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4043 - val_loss: 0.4407\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4039 - val_loss: 0.4401\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4037 - val_loss: 0.4415\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.4407\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4031 - val_loss: 0.4418\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4028 - val_loss: 0.4408\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4024 - val_loss: 0.4402\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4018 - val_loss: 0.4408\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4018 - val_loss: 0.4409\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4015 - val_loss: 0.4410\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4011 - val_loss: 0.4421\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4007 - val_loss: 0.4410\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4005 - val_loss: 0.4423\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4002 - val_loss: 0.4423\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4001 - val_loss: 0.4423\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4000 - val_loss: 0.4422\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3992 - val_loss: 0.4423\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3992 - val_loss: 0.4422\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3994 - val_loss: 0.4430\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3986 - val_loss: 0.4441\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3985 - val_loss: 0.4435\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3985 - val_loss: 0.4434\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3980 - val_loss: 0.4427\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3980 - val_loss: 0.4439\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3977 - val_loss: 0.4436\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3978 - val_loss: 0.4445\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 4ms/step - loss: 0.4372 - val_loss: 0.4305\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4257 - val_loss: 0.4286\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4231 - val_loss: 0.4265\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4217 - val_loss: 0.4261\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4202 - val_loss: 0.4271\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4193 - val_loss: 0.4262\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4181 - val_loss: 0.4259\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4172 - val_loss: 0.4264\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4160 - val_loss: 0.4257\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4155 - val_loss: 0.4269\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4141 - val_loss: 0.4259\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4137 - val_loss: 0.4277\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4134 - val_loss: 0.4270\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4124 - val_loss: 0.4268\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4117 - val_loss: 0.4278\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4113 - val_loss: 0.4276\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4110 - val_loss: 0.4274\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4099 - val_loss: 0.4281\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4101 - val_loss: 0.4273\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4093 - val_loss: 0.4286\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4090 - val_loss: 0.4279\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4081 - val_loss: 0.4267\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4077 - val_loss: 0.4288\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4073 - val_loss: 0.4295\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4074 - val_loss: 0.4285\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4067 - val_loss: 0.4285\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4069 - val_loss: 0.4294\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4065 - val_loss: 0.4290\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4059 - val_loss: 0.4300\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4055 - val_loss: 0.4296\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4057 - val_loss: 0.4306\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4047 - val_loss: 0.4300\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4045 - val_loss: 0.4299\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4305\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4037 - val_loss: 0.4343\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4036 - val_loss: 0.4320\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4032 - val_loss: 0.4312\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4031 - val_loss: 0.4308\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4030 - val_loss: 0.4317\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4023 - val_loss: 0.4316\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4021 - val_loss: 0.4321\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4019 - val_loss: 0.4343\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4020 - val_loss: 0.4314\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4016 - val_loss: 0.4330\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4010 - val_loss: 0.4341\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4013 - val_loss: 0.4341\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4006 - val_loss: 0.4350\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4005 - val_loss: 0.4347\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4002 - val_loss: 0.4359\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4000 - val_loss: 0.4348\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4307 - val_loss: 0.4398\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4222 - val_loss: 0.4377\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4190 - val_loss: 0.4361\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4179 - val_loss: 0.4343\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4157 - val_loss: 0.4342\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4156 - val_loss: 0.4327\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4146 - val_loss: 0.4329\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4136 - val_loss: 0.4327\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4124 - val_loss: 0.4336\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4120 - val_loss: 0.4340\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4114 - val_loss: 0.4335\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4331\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4102 - val_loss: 0.4336\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4098 - val_loss: 0.4338\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4094 - val_loss: 0.4345\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4090 - val_loss: 0.4342\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4085 - val_loss: 0.4342\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4080 - val_loss: 0.4353\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4355\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.4356\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4070 - val_loss: 0.4350\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4069 - val_loss: 0.4357\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4065 - val_loss: 0.4367\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4064 - val_loss: 0.4355\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4053 - val_loss: 0.4369\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4053 - val_loss: 0.4359\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4054 - val_loss: 0.4369\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4048 - val_loss: 0.4361\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4049 - val_loss: 0.4374\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4045 - val_loss: 0.4372\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4376\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4038 - val_loss: 0.4385\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4037 - val_loss: 0.4367\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4032 - val_loss: 0.4375\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4029 - val_loss: 0.4386\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4026 - val_loss: 0.4384\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4028 - val_loss: 0.4376\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4024 - val_loss: 0.4370\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4018 - val_loss: 0.4400\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4016 - val_loss: 0.4390\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4010 - val_loss: 0.4387\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4014 - val_loss: 0.4389\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4004 - val_loss: 0.4392\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4011 - val_loss: 0.4410\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4008 - val_loss: 0.4394\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4004 - val_loss: 0.4386\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3998 - val_loss: 0.4413\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4002 - val_loss: 0.4392\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3993 - val_loss: 0.4408\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3991 - val_loss: 0.4406\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4291 - val_loss: 0.4331\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4222 - val_loss: 0.4317\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4199 - val_loss: 0.4304\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4183 - val_loss: 0.4300\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4175 - val_loss: 0.4307\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4167 - val_loss: 0.4303\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4158 - val_loss: 0.4299\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4151 - val_loss: 0.4299\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4144 - val_loss: 0.4289\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4138 - val_loss: 0.4290\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4134 - val_loss: 0.4296\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4127 - val_loss: 0.4294\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4125 - val_loss: 0.4287\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4117 - val_loss: 0.4289\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4113 - val_loss: 0.4311\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4107 - val_loss: 0.4295\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4106 - val_loss: 0.4298\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4100 - val_loss: 0.4304\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4099 - val_loss: 0.4304\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4096 - val_loss: 0.4312\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4094 - val_loss: 0.4314\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4092 - val_loss: 0.4300\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4085 - val_loss: 0.4310\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4085 - val_loss: 0.4307\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4081 - val_loss: 0.4313\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4321\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4072 - val_loss: 0.4309\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4072 - val_loss: 0.4330\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4074 - val_loss: 0.4320\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4068 - val_loss: 0.4328\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4064 - val_loss: 0.4317\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4060 - val_loss: 0.4326\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4061 - val_loss: 0.4326\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4061 - val_loss: 0.4330\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4059 - val_loss: 0.4325\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4052 - val_loss: 0.4336\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4054 - val_loss: 0.4333\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4049 - val_loss: 0.4332\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4044 - val_loss: 0.4344\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4044 - val_loss: 0.4333\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4038 - val_loss: 0.4364\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4328\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4037 - val_loss: 0.4349\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4029 - val_loss: 0.4340\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4030 - val_loss: 0.4357\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4030 - val_loss: 0.4374\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4024 - val_loss: 0.4340\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4028 - val_loss: 0.4359\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4018 - val_loss: 0.4344\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4024 - val_loss: 0.4371\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4314 - val_loss: 0.4530\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4181 - val_loss: 0.4513\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4154 - val_loss: 0.4509\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4133 - val_loss: 0.4508\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4125 - val_loss: 0.4497\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4116 - val_loss: 0.4508\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4111 - val_loss: 0.4496\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4488\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4095 - val_loss: 0.4487\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4092 - val_loss: 0.4496\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4089 - val_loss: 0.4489\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4081 - val_loss: 0.4490\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.4483\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4068 - val_loss: 0.4492\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.4484\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4061 - val_loss: 0.4486\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4053 - val_loss: 0.4490\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4055 - val_loss: 0.4489\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4050 - val_loss: 0.4487\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4047 - val_loss: 0.4499\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4046 - val_loss: 0.4488\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4040 - val_loss: 0.4494\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4038 - val_loss: 0.4496\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4033 - val_loss: 0.4494\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4036 - val_loss: 0.4493\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.4499\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4027 - val_loss: 0.4496\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4024 - val_loss: 0.4500\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4019 - val_loss: 0.4506\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4022 - val_loss: 0.4490\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4014 - val_loss: 0.4497\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4015 - val_loss: 0.4517\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4014 - val_loss: 0.4507\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4009 - val_loss: 0.4497\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4005 - val_loss: 0.4512\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4009 - val_loss: 0.4507\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4004 - val_loss: 0.4507\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4001 - val_loss: 0.4505\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3998 - val_loss: 0.4515\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3994 - val_loss: 0.4501\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3995 - val_loss: 0.4515\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3993 - val_loss: 0.4508\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3991 - val_loss: 0.4509\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3989 - val_loss: 0.4516\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3983 - val_loss: 0.4524\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3987 - val_loss: 0.4522\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3983 - val_loss: 0.4534\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3983 - val_loss: 0.4522\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3978 - val_loss: 0.4529\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3975 - val_loss: 0.4528\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4412 - val_loss: 0.4015\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4312 - val_loss: 0.3998\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4288 - val_loss: 0.3995\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4271 - val_loss: 0.3992\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4258 - val_loss: 0.3995\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4247 - val_loss: 0.3994\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4234 - val_loss: 0.3998\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4228 - val_loss: 0.4001\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4218 - val_loss: 0.3999\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4218 - val_loss: 0.3997\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4205 - val_loss: 0.3997\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4205 - val_loss: 0.4003\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4195 - val_loss: 0.4005\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4194 - val_loss: 0.4021\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4188 - val_loss: 0.4003\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4184 - val_loss: 0.4006\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4176 - val_loss: 0.4006\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4173 - val_loss: 0.4021\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4168 - val_loss: 0.4020\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4165 - val_loss: 0.4032\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4161 - val_loss: 0.4034\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4159 - val_loss: 0.4036\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4159 - val_loss: 0.4050\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4153 - val_loss: 0.4039\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4148 - val_loss: 0.4049\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4146 - val_loss: 0.4051\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4141 - val_loss: 0.4045\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4138 - val_loss: 0.4054\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4130 - val_loss: 0.4051\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4132 - val_loss: 0.4044\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4130 - val_loss: 0.4047\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4126 - val_loss: 0.4051\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4123 - val_loss: 0.4052\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4122 - val_loss: 0.4048\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4120 - val_loss: 0.4049\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4117 - val_loss: 0.4052\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4070\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4112 - val_loss: 0.4062\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4112 - val_loss: 0.4053\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4106 - val_loss: 0.4063\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4075\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4099 - val_loss: 0.4069\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4099 - val_loss: 0.4085\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4096 - val_loss: 0.4065\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4094 - val_loss: 0.4073\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4090 - val_loss: 0.4092\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4092 - val_loss: 0.4083\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4086 - val_loss: 0.4093\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4083 - val_loss: 0.4103\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4089\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4307 - val_loss: 0.4380\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4218 - val_loss: 0.4355\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4190 - val_loss: 0.4343\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4178 - val_loss: 0.4333\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4165 - val_loss: 0.4320\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4155 - val_loss: 0.4319\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4146 - val_loss: 0.4317\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4142 - val_loss: 0.4322\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4137 - val_loss: 0.4317\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4134 - val_loss: 0.4327\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4129 - val_loss: 0.4315\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4123 - val_loss: 0.4326\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4122 - val_loss: 0.4314\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4116 - val_loss: 0.4314\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4111 - val_loss: 0.4343\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4319\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4319\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4104 - val_loss: 0.4331\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4101 - val_loss: 0.4325\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4096 - val_loss: 0.4329\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4091 - val_loss: 0.4340\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4089 - val_loss: 0.4331\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4086 - val_loss: 0.4332\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4083 - val_loss: 0.4348\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4082 - val_loss: 0.4338\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4076 - val_loss: 0.4340\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4074 - val_loss: 0.4334\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4069 - val_loss: 0.4350\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4069 - val_loss: 0.4353\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.4350\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4063 - val_loss: 0.4342\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4058 - val_loss: 0.4336\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4058 - val_loss: 0.4374\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4056 - val_loss: 0.4352\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4051 - val_loss: 0.4351\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4048 - val_loss: 0.4367\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4048 - val_loss: 0.4372\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4045 - val_loss: 0.4365\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4040 - val_loss: 0.4354\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4367\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4036 - val_loss: 0.4377\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4032 - val_loss: 0.4402\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4031 - val_loss: 0.4394\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4032 - val_loss: 0.4399\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4025 - val_loss: 0.4384\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4027 - val_loss: 0.4394\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4024 - val_loss: 0.4394\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4022 - val_loss: 0.4403\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4020 - val_loss: 0.4395\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4016 - val_loss: 0.4419\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4370 - val_loss: 0.4085\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4284 - val_loss: 0.4086\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4262 - val_loss: 0.4077\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4243 - val_loss: 0.4079\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4231 - val_loss: 0.4075\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4223 - val_loss: 0.4065\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4211 - val_loss: 0.4065\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4204 - val_loss: 0.4063\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4196 - val_loss: 0.4064\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4193 - val_loss: 0.4055\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4184 - val_loss: 0.4047\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4179 - val_loss: 0.4066\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4176 - val_loss: 0.4058\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4167 - val_loss: 0.4044\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4166 - val_loss: 0.4065\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4159 - val_loss: 0.4060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4158 - val_loss: 0.4070\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4150 - val_loss: 0.4054\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4146 - val_loss: 0.4056\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4145 - val_loss: 0.4065\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4140 - val_loss: 0.4078\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4137 - val_loss: 0.4061\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4130 - val_loss: 0.4069\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4129 - val_loss: 0.4060\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4124 - val_loss: 0.4069\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4118 - val_loss: 0.4082\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4116 - val_loss: 0.4085\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4116 - val_loss: 0.4074\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4107 - val_loss: 0.4059\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4091\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4081\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4101 - val_loss: 0.4063\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4101 - val_loss: 0.4078\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4096 - val_loss: 0.4079\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4092 - val_loss: 0.4074\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4091 - val_loss: 0.4082\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4089 - val_loss: 0.4090\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4091 - val_loss: 0.4072\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4085 - val_loss: 0.4087\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4081 - val_loss: 0.4119\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4081 - val_loss: 0.4100\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4078 - val_loss: 0.4094\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4072 - val_loss: 0.4084\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4077 - val_loss: 0.4103\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4069 - val_loss: 0.4085\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4073 - val_loss: 0.4117\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4066 - val_loss: 0.4099\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4070 - val_loss: 0.4099\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4061 - val_loss: 0.4121\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4060 - val_loss: 0.4110\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "70\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4373 - val_loss: 0.4064\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4293 - val_loss: 0.4044\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4265 - val_loss: 0.4034\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4248 - val_loss: 0.4025\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4233 - val_loss: 0.4035\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4224 - val_loss: 0.4041\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4217 - val_loss: 0.4045\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4211 - val_loss: 0.4041\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4203 - val_loss: 0.4042\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4197 - val_loss: 0.4045\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4191 - val_loss: 0.4041\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4185 - val_loss: 0.4057\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4181 - val_loss: 0.4044\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4176 - val_loss: 0.4051\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4172 - val_loss: 0.4063\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4168 - val_loss: 0.4060\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4162 - val_loss: 0.4053\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4159 - val_loss: 0.4060\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4154 - val_loss: 0.4061\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4149 - val_loss: 0.4085\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4144 - val_loss: 0.4072\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4140 - val_loss: 0.4081\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4136 - val_loss: 0.4073\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4136 - val_loss: 0.4078\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4130 - val_loss: 0.4088\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4128 - val_loss: 0.4100\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4123 - val_loss: 0.4089\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4119 - val_loss: 0.4092\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4117 - val_loss: 0.4097\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4113 - val_loss: 0.4098\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4111 - val_loss: 0.4105\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4108 - val_loss: 0.4106\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4106 - val_loss: 0.4103\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4107 - val_loss: 0.4112\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4101 - val_loss: 0.4130\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4100 - val_loss: 0.4109\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4094 - val_loss: 0.4115\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4092 - val_loss: 0.4109\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4091 - val_loss: 0.4137\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4090 - val_loss: 0.4121\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4088 - val_loss: 0.4138\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4086 - val_loss: 0.4117\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4085 - val_loss: 0.4145\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4087 - val_loss: 0.4150\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4080 - val_loss: 0.4150\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4076 - val_loss: 0.4142\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4076 - val_loss: 0.4136\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4078 - val_loss: 0.4134\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4070 - val_loss: 0.4149\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4067 - val_loss: 0.4142\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4216 - val_loss: 0.4692\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4144 - val_loss: 0.4672\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4121 - val_loss: 0.4674\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4107 - val_loss: 0.4669\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4092 - val_loss: 0.4675\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4083 - val_loss: 0.4663\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.4663\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4067 - val_loss: 0.4655\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4664\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4054 - val_loss: 0.4675\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4047 - val_loss: 0.4655\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4042 - val_loss: 0.4660\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4036 - val_loss: 0.4657\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4034 - val_loss: 0.4672\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4026 - val_loss: 0.4664\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4024 - val_loss: 0.4668\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4020 - val_loss: 0.4671\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4013 - val_loss: 0.4677\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4012 - val_loss: 0.4679\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4007 - val_loss: 0.4680\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4002 - val_loss: 0.4677\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3998 - val_loss: 0.4689\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3996 - val_loss: 0.4707\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3998 - val_loss: 0.4701\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3993 - val_loss: 0.4703\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3989 - val_loss: 0.4691\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3987 - val_loss: 0.4700\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3983 - val_loss: 0.4723\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3981 - val_loss: 0.4712\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3981 - val_loss: 0.4710\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3976 - val_loss: 0.4696\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3974 - val_loss: 0.4711\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3970 - val_loss: 0.4717\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3969 - val_loss: 0.4700\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3967 - val_loss: 0.4718\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3966 - val_loss: 0.4709\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3966 - val_loss: 0.4706\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3962 - val_loss: 0.4708\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3958 - val_loss: 0.4728\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3960 - val_loss: 0.4732\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3953 - val_loss: 0.4714\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3955 - val_loss: 0.4722\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3949 - val_loss: 0.4753\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3950 - val_loss: 0.4750\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3948 - val_loss: 0.4760\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3947 - val_loss: 0.4701\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3944 - val_loss: 0.4757\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3937 - val_loss: 0.4738\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3939 - val_loss: 0.4736\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3939 - val_loss: 0.4726\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4446 - val_loss: 0.3962\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4332 - val_loss: 0.3937\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4297 - val_loss: 0.3929\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4279 - val_loss: 0.3929\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4264 - val_loss: 0.3925\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4253 - val_loss: 0.3926\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4247 - val_loss: 0.3917\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4236 - val_loss: 0.3914\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4229 - val_loss: 0.3920\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4225 - val_loss: 0.3910\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4216 - val_loss: 0.3919\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4213 - val_loss: 0.3910\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4204 - val_loss: 0.3932\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4204 - val_loss: 0.3918\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4197 - val_loss: 0.3931\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4194 - val_loss: 0.3925\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4188 - val_loss: 0.3932\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4184 - val_loss: 0.3932\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4181 - val_loss: 0.3932\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4177 - val_loss: 0.3938\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4175 - val_loss: 0.3937\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4169 - val_loss: 0.3939\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4164 - val_loss: 0.3943\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4163 - val_loss: 0.3949\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4157 - val_loss: 0.3940\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4153 - val_loss: 0.3942\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4150 - val_loss: 0.3943\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4148 - val_loss: 0.3946\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4146 - val_loss: 0.3952\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4143 - val_loss: 0.3962\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4138 - val_loss: 0.3942\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4133 - val_loss: 0.3958\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4129 - val_loss: 0.3953\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4129 - val_loss: 0.3963\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4123 - val_loss: 0.3961\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4119 - val_loss: 0.3974\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4121 - val_loss: 0.3961\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4113 - val_loss: 0.3978\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4114 - val_loss: 0.3992\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4110 - val_loss: 0.3974\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.3983\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4102 - val_loss: 0.3987\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4103 - val_loss: 0.3984\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4100 - val_loss: 0.3982\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4086 - val_loss: 0.3997\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4092 - val_loss: 0.3996\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4089 - val_loss: 0.3998\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4087 - val_loss: 0.4013\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4084 - val_loss: 0.4000\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4086 - val_loss: 0.4003\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4377 - val_loss: 0.4209\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4289 - val_loss: 0.4196\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4263 - val_loss: 0.4173\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4239 - val_loss: 0.4167\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4219 - val_loss: 0.4152\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4211 - val_loss: 0.4157\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4201 - val_loss: 0.4151\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4191 - val_loss: 0.4149\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4183 - val_loss: 0.4146\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4176 - val_loss: 0.4155\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4170 - val_loss: 0.4151\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4164 - val_loss: 0.4140\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4158 - val_loss: 0.4138\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4154 - val_loss: 0.4140\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4148 - val_loss: 0.4132\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4143 - val_loss: 0.4145\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4137 - val_loss: 0.4136\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4132 - val_loss: 0.4166\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4135 - val_loss: 0.4141\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4126 - val_loss: 0.4163\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4120 - val_loss: 0.4148\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4123 - val_loss: 0.4141\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4138\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4112 - val_loss: 0.4143\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4144\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4103 - val_loss: 0.4172\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4101 - val_loss: 0.4144\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4097 - val_loss: 0.4159\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4100 - val_loss: 0.4160\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4092 - val_loss: 0.4164\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4095 - val_loss: 0.4159\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4088 - val_loss: 0.4189\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4087 - val_loss: 0.4168\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4080 - val_loss: 0.4152\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4084 - val_loss: 0.4176\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4080 - val_loss: 0.4171\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4074 - val_loss: 0.4196\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4069 - val_loss: 0.4188\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4066 - val_loss: 0.4168\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4066 - val_loss: 0.4164\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4062 - val_loss: 0.4163\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4060 - val_loss: 0.4207\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4057 - val_loss: 0.4174\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4056 - val_loss: 0.4182\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4053 - val_loss: 0.4213\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4047 - val_loss: 0.4188\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4050 - val_loss: 0.4181\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4045 - val_loss: 0.4155\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4044 - val_loss: 0.4187\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4041 - val_loss: 0.4180\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4364 - val_loss: 0.4128\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4285 - val_loss: 0.4096\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4261 - val_loss: 0.4086\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4246 - val_loss: 0.4075\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4236 - val_loss: 0.4080\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4228 - val_loss: 0.4084\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4222 - val_loss: 0.4073\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4214 - val_loss: 0.4066\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4212 - val_loss: 0.4064\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4205 - val_loss: 0.4061\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4201 - val_loss: 0.4064\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4198 - val_loss: 0.4063\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4194 - val_loss: 0.4055\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4187 - val_loss: 0.4082\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4182 - val_loss: 0.4068\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4176 - val_loss: 0.4072\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4176 - val_loss: 0.4069\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4171 - val_loss: 0.4069\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4164 - val_loss: 0.4058\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4162 - val_loss: 0.4062\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4157 - val_loss: 0.4066\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4153 - val_loss: 0.4064\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4151 - val_loss: 0.4067\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4146 - val_loss: 0.4057\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4142 - val_loss: 0.4069\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4141 - val_loss: 0.4057\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4141 - val_loss: 0.4068\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4137 - val_loss: 0.4063\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4131 - val_loss: 0.4064\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4133 - val_loss: 0.4073\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4125 - val_loss: 0.4074\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4125 - val_loss: 0.4062\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4123 - val_loss: 0.4062\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4119 - val_loss: 0.4069\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4119 - val_loss: 0.4078\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4074\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4081\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4108 - val_loss: 0.4076\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4106 - val_loss: 0.4080\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4106 - val_loss: 0.4085\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4104 - val_loss: 0.4079\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4102 - val_loss: 0.4080\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4101 - val_loss: 0.4076\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4095 - val_loss: 0.4075\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4095 - val_loss: 0.4078\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4095 - val_loss: 0.4084\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4094 - val_loss: 0.4064\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4085 - val_loss: 0.4086\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4088 - val_loss: 0.4079\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4089 - val_loss: 0.4082\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 4ms/step - loss: 0.4360 - val_loss: 0.4163\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4271 - val_loss: 0.4136\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4247 - val_loss: 0.4111\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4234 - val_loss: 0.4125\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4225 - val_loss: 0.4106\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4217 - val_loss: 0.4108\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4210 - val_loss: 0.4103\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4204 - val_loss: 0.4092\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4198 - val_loss: 0.4087\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4191 - val_loss: 0.4097\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4182 - val_loss: 0.4098\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4177 - val_loss: 0.4094\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4173 - val_loss: 0.4086\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4168 - val_loss: 0.4099\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4160 - val_loss: 0.4087\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4160 - val_loss: 0.4087\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4151 - val_loss: 0.4111\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4149 - val_loss: 0.4090\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4145 - val_loss: 0.4096\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4143 - val_loss: 0.4091\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4136 - val_loss: 0.4105\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4135 - val_loss: 0.4098\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4131 - val_loss: 0.4112\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4127 - val_loss: 0.4087\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4121 - val_loss: 0.4090\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4120 - val_loss: 0.4093\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4117 - val_loss: 0.4094\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4114 - val_loss: 0.4090\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4110 - val_loss: 0.4111\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4107 - val_loss: 0.4102\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4098\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4099 - val_loss: 0.4102\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4102 - val_loss: 0.4100\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4096 - val_loss: 0.4129\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4093 - val_loss: 0.4105\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4091 - val_loss: 0.4097\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4083 - val_loss: 0.4103\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4080 - val_loss: 0.4117\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4078 - val_loss: 0.4118\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4080 - val_loss: 0.4118\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4096\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4072 - val_loss: 0.4122\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4066 - val_loss: 0.4105\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4067 - val_loss: 0.4112\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4059 - val_loss: 0.4126\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4060 - val_loss: 0.4116\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4056 - val_loss: 0.4117\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4059 - val_loss: 0.4130\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4052 - val_loss: 0.4109\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4046 - val_loss: 0.4123\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4368 - val_loss: 0.4266\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4240 - val_loss: 0.4247\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4215 - val_loss: 0.4228\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4204 - val_loss: 0.4229\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4196 - val_loss: 0.4233\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4190 - val_loss: 0.4226\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4183 - val_loss: 0.4227\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4175 - val_loss: 0.4219\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4173 - val_loss: 0.4226\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4165 - val_loss: 0.4231\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4162 - val_loss: 0.4224\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4157 - val_loss: 0.4218\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4154 - val_loss: 0.4214\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4150 - val_loss: 0.4220\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4145 - val_loss: 0.4220\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4140 - val_loss: 0.4217\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4132 - val_loss: 0.4232\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4129 - val_loss: 0.4230\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4125 - val_loss: 0.4211\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4120 - val_loss: 0.4207\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4116 - val_loss: 0.4219\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4227\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4218\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4221\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4103 - val_loss: 0.4227\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4098 - val_loss: 0.4224\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4099 - val_loss: 0.4218\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4091 - val_loss: 0.4223\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4087 - val_loss: 0.4216\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4077 - val_loss: 0.4241\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4081 - val_loss: 0.4233\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4077 - val_loss: 0.4230\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4073 - val_loss: 0.4225\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4070 - val_loss: 0.4227\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4069 - val_loss: 0.4244\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4068 - val_loss: 0.4227\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.4229\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4060 - val_loss: 0.4232\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4055 - val_loss: 0.4235\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4059 - val_loss: 0.4243\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4055 - val_loss: 0.4247\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4235\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4049 - val_loss: 0.4255\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4049 - val_loss: 0.4271\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4043 - val_loss: 0.4264\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4046 - val_loss: 0.4267\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4039 - val_loss: 0.4267\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4040 - val_loss: 0.4261\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4037 - val_loss: 0.4263\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4033 - val_loss: 0.4257\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4356 - val_loss: 0.4244\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4253 - val_loss: 0.4220\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4225 - val_loss: 0.4218\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4208 - val_loss: 0.4213\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4201 - val_loss: 0.4209\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4187 - val_loss: 0.4201\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4182 - val_loss: 0.4205\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4176 - val_loss: 0.4205\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4172 - val_loss: 0.4201\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4165 - val_loss: 0.4211\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4162 - val_loss: 0.4202\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4156 - val_loss: 0.4205\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4153 - val_loss: 0.4199\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4150 - val_loss: 0.4205\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4140 - val_loss: 0.4199\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4136 - val_loss: 0.4208\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4134 - val_loss: 0.4209\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4132 - val_loss: 0.4209\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4125 - val_loss: 0.4214\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4121 - val_loss: 0.4212\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4118 - val_loss: 0.4208\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4113 - val_loss: 0.4212\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4230\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4103 - val_loss: 0.4235\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4102 - val_loss: 0.4226\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4096 - val_loss: 0.4231\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4092 - val_loss: 0.4225\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4090 - val_loss: 0.4229\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4089 - val_loss: 0.4235\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4079 - val_loss: 0.4234\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4237\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4075 - val_loss: 0.4255\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4068 - val_loss: 0.4257\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4072 - val_loss: 0.4258\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4066 - val_loss: 0.4263\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4066 - val_loss: 0.4262\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4266\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4056 - val_loss: 0.4284\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4053 - val_loss: 0.4289\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4050 - val_loss: 0.4267\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4046 - val_loss: 0.4297\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4044 - val_loss: 0.4292\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4036 - val_loss: 0.4291\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4038 - val_loss: 0.4318\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4031 - val_loss: 0.4297\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.4293\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4026 - val_loss: 0.4319\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4024 - val_loss: 0.4348\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4021 - val_loss: 0.4336\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4021 - val_loss: 0.4344\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4341 - val_loss: 0.4221\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4245 - val_loss: 0.4200\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4223 - val_loss: 0.4197\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4209 - val_loss: 0.4199\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4198 - val_loss: 0.4194\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4187 - val_loss: 0.4217\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4179 - val_loss: 0.4215\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4171 - val_loss: 0.4221\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4167 - val_loss: 0.4208\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4160 - val_loss: 0.4197\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4154 - val_loss: 0.4206\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4149 - val_loss: 0.4209\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4144 - val_loss: 0.4211\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4137 - val_loss: 0.4232\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4134 - val_loss: 0.4200\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4130 - val_loss: 0.4204\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4124 - val_loss: 0.4201\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4122 - val_loss: 0.4210\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4117 - val_loss: 0.4203\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4112 - val_loss: 0.4202\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4107 - val_loss: 0.4216\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4107 - val_loss: 0.4215\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4103 - val_loss: 0.4204\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4098 - val_loss: 0.4221\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4096 - val_loss: 0.4215\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4090 - val_loss: 0.4201\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4089 - val_loss: 0.4216\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4083 - val_loss: 0.4226\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4081 - val_loss: 0.4209\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4081 - val_loss: 0.4208\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4074 - val_loss: 0.4234\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4076 - val_loss: 0.4226\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4070 - val_loss: 0.4206\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4068 - val_loss: 0.4213\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4069 - val_loss: 0.4229\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4067 - val_loss: 0.4218\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4062 - val_loss: 0.4217\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4060 - val_loss: 0.4204\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4059 - val_loss: 0.4204\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4054 - val_loss: 0.4216\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4053 - val_loss: 0.4228\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4053 - val_loss: 0.4207\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4050 - val_loss: 0.4221\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4048 - val_loss: 0.4211\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4049 - val_loss: 0.4229\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4042 - val_loss: 0.4200\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4042 - val_loss: 0.4213\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4040 - val_loss: 0.4196\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4244\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4037 - val_loss: 0.4232\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 0.4270 - val_loss: 0.4393\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4206 - val_loss: 0.4384\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4186 - val_loss: 0.4367\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4170 - val_loss: 0.4359\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4163 - val_loss: 0.4351\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4153 - val_loss: 0.4350\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4147 - val_loss: 0.4341\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4141 - val_loss: 0.4346\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4136 - val_loss: 0.4341\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4129 - val_loss: 0.4344\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4124 - val_loss: 0.4347\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4120 - val_loss: 0.4343\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4113 - val_loss: 0.4345\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4105 - val_loss: 0.4362\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4358\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4101 - val_loss: 0.4353\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4096 - val_loss: 0.4358\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4088 - val_loss: 0.4356\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4083 - val_loss: 0.4355\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4357\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4077 - val_loss: 0.4369\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4070 - val_loss: 0.4375\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4068 - val_loss: 0.4373\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.4380\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4057 - val_loss: 0.4382\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4056 - val_loss: 0.4376\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4049 - val_loss: 0.4380\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4047 - val_loss: 0.4384\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4042 - val_loss: 0.4381\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4394\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4036 - val_loss: 0.4394\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4032 - val_loss: 0.4396\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4023 - val_loss: 0.4404\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4024 - val_loss: 0.4409\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4019 - val_loss: 0.4412\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4018 - val_loss: 0.4412\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4016 - val_loss: 0.4418\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4006 - val_loss: 0.4423\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4007 - val_loss: 0.4429\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4007 - val_loss: 0.4428\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4001 - val_loss: 0.4426\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3999 - val_loss: 0.4420\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3990 - val_loss: 0.4458\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3992 - val_loss: 0.4433\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3986 - val_loss: 0.4455\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3984 - val_loss: 0.4482\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3985 - val_loss: 0.4455\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3980 - val_loss: 0.4442\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3972 - val_loss: 0.4462\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3978 - val_loss: 0.4460\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "80\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4195 - val_loss: 0.4641\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4131 - val_loss: 0.4641\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4110 - val_loss: 0.4636\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4098 - val_loss: 0.4641\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4086 - val_loss: 0.4633\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.4640\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4071 - val_loss: 0.4658\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4062 - val_loss: 0.4639\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4056 - val_loss: 0.4656\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4050 - val_loss: 0.4645\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4044 - val_loss: 0.4650\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4042 - val_loss: 0.4654\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4034 - val_loss: 0.4652\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4028 - val_loss: 0.4665\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4026 - val_loss: 0.4664\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4021 - val_loss: 0.4664\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4020 - val_loss: 0.4662\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4012 - val_loss: 0.4673\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4012 - val_loss: 0.4676\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4008 - val_loss: 0.4677\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4002 - val_loss: 0.4688\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4003 - val_loss: 0.4678\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3997 - val_loss: 0.4695\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3993 - val_loss: 0.4694\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3988 - val_loss: 0.4699\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3988 - val_loss: 0.4708\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3984 - val_loss: 0.4693\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3986 - val_loss: 0.4692\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3980 - val_loss: 0.4699\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3979 - val_loss: 0.4711\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3974 - val_loss: 0.4708\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3974 - val_loss: 0.4706\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3973 - val_loss: 0.4722\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3969 - val_loss: 0.4718\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3966 - val_loss: 0.4727\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3961 - val_loss: 0.4724\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3961 - val_loss: 0.4740\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3960 - val_loss: 0.4723\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3956 - val_loss: 0.4727\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3957 - val_loss: 0.4739\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3957 - val_loss: 0.4742\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3951 - val_loss: 0.4734\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3952 - val_loss: 0.4740\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3946 - val_loss: 0.4750\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3947 - val_loss: 0.4751\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3945 - val_loss: 0.4766\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3946 - val_loss: 0.4763\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3942 - val_loss: 0.4747\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3935 - val_loss: 0.4755\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3936 - val_loss: 0.4748\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4367 - val_loss: 0.4257\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4250 - val_loss: 0.4232\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4223 - val_loss: 0.4226\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4203 - val_loss: 0.4227\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4194 - val_loss: 0.4217\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4189 - val_loss: 0.4221\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4182 - val_loss: 0.4216\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4176 - val_loss: 0.4217\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4171 - val_loss: 0.4224\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4167 - val_loss: 0.4218\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4161 - val_loss: 0.4220\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4158 - val_loss: 0.4222\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4153 - val_loss: 0.4223\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4150 - val_loss: 0.4230\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4141 - val_loss: 0.4228\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4139 - val_loss: 0.4229\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4134 - val_loss: 0.4224\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4130 - val_loss: 0.4218\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4124 - val_loss: 0.4208\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4122 - val_loss: 0.4210\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4117 - val_loss: 0.4213\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4112 - val_loss: 0.4244\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4109 - val_loss: 0.4218\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4104 - val_loss: 0.4235\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4097 - val_loss: 0.4241\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4095 - val_loss: 0.4234\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4089 - val_loss: 0.4243\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4088 - val_loss: 0.4232\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4082 - val_loss: 0.4229\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4081 - val_loss: 0.4223\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.4261\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4074 - val_loss: 0.4238\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4071 - val_loss: 0.4226\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4065 - val_loss: 0.4259\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4069 - val_loss: 0.4249\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4063 - val_loss: 0.4253\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4058 - val_loss: 0.4243\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4061 - val_loss: 0.4256\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4057 - val_loss: 0.4249\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4051 - val_loss: 0.4251\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4053 - val_loss: 0.4274\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4050 - val_loss: 0.4265\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4050 - val_loss: 0.4264\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4043 - val_loss: 0.4254\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4262\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4283\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4036 - val_loss: 0.4258\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4039 - val_loss: 0.4270\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4032 - val_loss: 0.4269\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4030 - val_loss: 0.4273\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4394 - val_loss: 0.4210\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4256 - val_loss: 0.4175\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4235 - val_loss: 0.4166\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4221 - val_loss: 0.4165\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4211 - val_loss: 0.4159\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4201 - val_loss: 0.4161\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4192 - val_loss: 0.4155\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4187 - val_loss: 0.4157\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4180 - val_loss: 0.4161\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4175 - val_loss: 0.4160\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4169 - val_loss: 0.4162\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4164 - val_loss: 0.4157\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4162 - val_loss: 0.4154\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4153 - val_loss: 0.4174\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4149 - val_loss: 0.4169\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4144 - val_loss: 0.4181\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4142 - val_loss: 0.4167\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4135 - val_loss: 0.4175\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4131 - val_loss: 0.4179\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4127 - val_loss: 0.4178\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4122 - val_loss: 0.4170\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4124 - val_loss: 0.4188\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4118 - val_loss: 0.4168\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4111 - val_loss: 0.4182\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4106 - val_loss: 0.4181\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4103 - val_loss: 0.4179\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4104 - val_loss: 0.4204\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4099 - val_loss: 0.4200\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4099 - val_loss: 0.4186\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4094 - val_loss: 0.4187\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4096 - val_loss: 0.4184\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4090 - val_loss: 0.4176\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4088 - val_loss: 0.4182\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4086 - val_loss: 0.4187\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4081 - val_loss: 0.4198\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4082 - val_loss: 0.4202\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4078 - val_loss: 0.4192\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4073 - val_loss: 0.4202\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4070 - val_loss: 0.4202\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4073 - val_loss: 0.4188\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4068 - val_loss: 0.4189\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4068 - val_loss: 0.4193\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4067 - val_loss: 0.4210\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4063 - val_loss: 0.4213\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4063 - val_loss: 0.4191\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4056 - val_loss: 0.4208\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4057 - val_loss: 0.4213\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4054 - val_loss: 0.4208\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4047 - val_loss: 0.4202\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4047 - val_loss: 0.4223\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4252 - val_loss: 0.4492\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4175 - val_loss: 0.4483\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4157 - val_loss: 0.4483\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4143 - val_loss: 0.4471\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4131 - val_loss: 0.4469\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4119 - val_loss: 0.4469\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4114 - val_loss: 0.4455\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4107 - val_loss: 0.4454\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4100 - val_loss: 0.4473\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4094 - val_loss: 0.4466\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4086 - val_loss: 0.4460\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4078 - val_loss: 0.4449\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4074 - val_loss: 0.4458\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4070 - val_loss: 0.4467\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4067 - val_loss: 0.4467\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4062 - val_loss: 0.4459\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4057 - val_loss: 0.4468\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4052 - val_loss: 0.4481\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4048 - val_loss: 0.4472\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4045 - val_loss: 0.4485\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4038 - val_loss: 0.4484\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4033 - val_loss: 0.4500\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4032 - val_loss: 0.4482\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4024 - val_loss: 0.4496\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4022 - val_loss: 0.4484\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4017 - val_loss: 0.4503\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4011 - val_loss: 0.4516\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4008 - val_loss: 0.4497\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4008 - val_loss: 0.4497\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4003 - val_loss: 0.4521\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3999 - val_loss: 0.4509\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3997 - val_loss: 0.4514\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3998 - val_loss: 0.4504\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3990 - val_loss: 0.4536\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3989 - val_loss: 0.4524\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3989 - val_loss: 0.4530\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3984 - val_loss: 0.4530\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3980 - val_loss: 0.4524\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3977 - val_loss: 0.4524\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3972 - val_loss: 0.4527\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3969 - val_loss: 0.4536\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3973 - val_loss: 0.4542\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3969 - val_loss: 0.4525\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3967 - val_loss: 0.4562\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3962 - val_loss: 0.4516\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3963 - val_loss: 0.4586\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3957 - val_loss: 0.4548\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3956 - val_loss: 0.4547\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3953 - val_loss: 0.4574\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3949 - val_loss: 0.4555\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4292 - val_loss: 0.4338\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4215 - val_loss: 0.4324\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4202 - val_loss: 0.4314\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4192 - val_loss: 0.4311\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4183 - val_loss: 0.4313\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4173 - val_loss: 0.4319\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4167 - val_loss: 0.4310\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4159 - val_loss: 0.4314\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4155 - val_loss: 0.4307\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4151 - val_loss: 0.4301\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4143 - val_loss: 0.4317\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4141 - val_loss: 0.4327\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4138 - val_loss: 0.4321\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4133 - val_loss: 0.4315\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4129 - val_loss: 0.4335\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4126 - val_loss: 0.4334\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4122 - val_loss: 0.4334\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4119 - val_loss: 0.4343\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4114 - val_loss: 0.4349\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4112 - val_loss: 0.4351\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4109 - val_loss: 0.4350\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4104 - val_loss: 0.4364\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4102 - val_loss: 0.4369\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4099 - val_loss: 0.4383\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4092 - val_loss: 0.4375\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4093 - val_loss: 0.4393\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4089 - val_loss: 0.4384\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4088 - val_loss: 0.4388\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4084 - val_loss: 0.4412\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4078 - val_loss: 0.4398\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4078 - val_loss: 0.4437\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4078 - val_loss: 0.4428\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4074 - val_loss: 0.4444\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4068 - val_loss: 0.4425\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4073 - val_loss: 0.4447\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4067 - val_loss: 0.4450\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4065 - val_loss: 0.4446\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4063 - val_loss: 0.4483\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4474\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4060 - val_loss: 0.4466\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4056 - val_loss: 0.4461\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4055 - val_loss: 0.4483\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4047 - val_loss: 0.4477\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4048 - val_loss: 0.4491\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4050 - val_loss: 0.4482\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4044 - val_loss: 0.4504\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4043 - val_loss: 0.4512\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4038 - val_loss: 0.4492\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4038 - val_loss: 0.4537\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4033 - val_loss: 0.4503\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4379 - val_loss: 0.4046\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4287 - val_loss: 0.4042\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4264 - val_loss: 0.4048\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4249 - val_loss: 0.4036\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4243 - val_loss: 0.4032\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4230 - val_loss: 0.4024\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4224 - val_loss: 0.4040\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4212 - val_loss: 0.4021\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4209 - val_loss: 0.4013\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4204 - val_loss: 0.4062\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4198 - val_loss: 0.4065\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4193 - val_loss: 0.4031\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4190 - val_loss: 0.4050\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4183 - val_loss: 0.4029\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4177 - val_loss: 0.4037\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4177 - val_loss: 0.4028\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4170 - val_loss: 0.4026\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4168 - val_loss: 0.4046\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4162 - val_loss: 0.4062\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4160 - val_loss: 0.4053\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4155 - val_loss: 0.4058\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4151 - val_loss: 0.4049\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4149 - val_loss: 0.4081\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4143 - val_loss: 0.4099\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4142 - val_loss: 0.4076\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4137 - val_loss: 0.4079\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4135 - val_loss: 0.4066\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4133 - val_loss: 0.4064\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4130 - val_loss: 0.4065\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4125 - val_loss: 0.4077\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4123 - val_loss: 0.4077\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4119 - val_loss: 0.4091\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4116 - val_loss: 0.4066\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4113 - val_loss: 0.4068\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4114 - val_loss: 0.4100\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4110 - val_loss: 0.4072\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4104 - val_loss: 0.4131\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4111\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4101 - val_loss: 0.4110\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4100 - val_loss: 0.4108\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4098 - val_loss: 0.4142\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4097 - val_loss: 0.4102\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4098 - val_loss: 0.4116\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4096 - val_loss: 0.4112\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4090 - val_loss: 0.4109\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4090 - val_loss: 0.4152\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4083 - val_loss: 0.4213\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4084 - val_loss: 0.4156\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4084 - val_loss: 0.4136\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4076 - val_loss: 0.4115\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4288 - val_loss: 0.4629\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4169 - val_loss: 0.4599\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4128 - val_loss: 0.4608\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4584\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4096 - val_loss: 0.4609\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4087 - val_loss: 0.4599\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4078 - val_loss: 0.4597\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4072 - val_loss: 0.4603\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4068 - val_loss: 0.4596\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4055 - val_loss: 0.4610\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4054 - val_loss: 0.4613\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4051 - val_loss: 0.4610\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4046 - val_loss: 0.4620\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4040 - val_loss: 0.4639\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4039 - val_loss: 0.4616\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4037 - val_loss: 0.4613\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.4623\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4023 - val_loss: 0.4639\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4023 - val_loss: 0.4619\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4021 - val_loss: 0.4630\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4018 - val_loss: 0.4637\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4015 - val_loss: 0.4634\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4012 - val_loss: 0.4631\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4010 - val_loss: 0.4635\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4008 - val_loss: 0.4635\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4007 - val_loss: 0.4617\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3999 - val_loss: 0.4635\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3998 - val_loss: 0.4627\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3994 - val_loss: 0.4632\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3999 - val_loss: 0.4635\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3991 - val_loss: 0.4619\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3987 - val_loss: 0.4643\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3986 - val_loss: 0.4629\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3985 - val_loss: 0.4638\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3982 - val_loss: 0.4630\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3980 - val_loss: 0.4639\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3970 - val_loss: 0.4653\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3974 - val_loss: 0.4659\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3976 - val_loss: 0.4655\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3972 - val_loss: 0.4640\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3971 - val_loss: 0.4647\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3969 - val_loss: 0.4648\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3963 - val_loss: 0.4660\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3963 - val_loss: 0.4673\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3958 - val_loss: 0.4673\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3960 - val_loss: 0.4648\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3955 - val_loss: 0.4659\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3955 - val_loss: 0.4650\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3950 - val_loss: 0.4701\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3951 - val_loss: 0.4638\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4352 - val_loss: 0.4159\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4265 - val_loss: 0.4148\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4240 - val_loss: 0.4130\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4229 - val_loss: 0.4140\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4218 - val_loss: 0.4120\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4210 - val_loss: 0.4137\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4202 - val_loss: 0.4136\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4194 - val_loss: 0.4131\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4187 - val_loss: 0.4124\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4179 - val_loss: 0.4137\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4172 - val_loss: 0.4126\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4167 - val_loss: 0.4134\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4161 - val_loss: 0.4138\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4158 - val_loss: 0.4125\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4151 - val_loss: 0.4121\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4144 - val_loss: 0.4148\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4142 - val_loss: 0.4150\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4136 - val_loss: 0.4154\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4134 - val_loss: 0.4162\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4124 - val_loss: 0.4145\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4129 - val_loss: 0.4159\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4120 - val_loss: 0.4156\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4118 - val_loss: 0.4168\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4112 - val_loss: 0.4161\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4109 - val_loss: 0.4161\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4104 - val_loss: 0.4175\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4103 - val_loss: 0.4177\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4103 - val_loss: 0.4181\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4097 - val_loss: 0.4188\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4091 - val_loss: 0.4181\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4088 - val_loss: 0.4197\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4087 - val_loss: 0.4202\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4080 - val_loss: 0.4198\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4207\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4077 - val_loss: 0.4215\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4071 - val_loss: 0.4199\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.4235\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4062 - val_loss: 0.4220\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4062 - val_loss: 0.4230\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4234\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4053 - val_loss: 0.4233\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4052 - val_loss: 0.4222\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4046 - val_loss: 0.4274\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4042 - val_loss: 0.4243\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4043 - val_loss: 0.4296\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4241\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4037 - val_loss: 0.4253\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4036 - val_loss: 0.4325\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4029 - val_loss: 0.4263\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4028 - val_loss: 0.4287\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4416 - val_loss: 0.4301\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4274 - val_loss: 0.4278\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4249 - val_loss: 0.4270\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4229 - val_loss: 0.4274\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4214 - val_loss: 0.4271\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4201 - val_loss: 0.4273\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4192 - val_loss: 0.4261\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4181 - val_loss: 0.4262\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4174 - val_loss: 0.4269\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4171 - val_loss: 0.4259\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4163 - val_loss: 0.4266\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4157 - val_loss: 0.4275\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4152 - val_loss: 0.4284\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4144 - val_loss: 0.4289\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4139 - val_loss: 0.4286\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4132 - val_loss: 0.4291\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4129 - val_loss: 0.4294\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4122 - val_loss: 0.4297\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4118 - val_loss: 0.4324\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4113 - val_loss: 0.4296\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4108 - val_loss: 0.4296\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4102 - val_loss: 0.4303\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4098 - val_loss: 0.4304\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4089 - val_loss: 0.4348\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4086 - val_loss: 0.4304\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4082 - val_loss: 0.4312\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.4356\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4070 - val_loss: 0.4322\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4067 - val_loss: 0.4318\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4063 - val_loss: 0.4324\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4059 - val_loss: 0.4326\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4058 - val_loss: 0.4330\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4052 - val_loss: 0.4357\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4049 - val_loss: 0.4336\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4043 - val_loss: 0.4345\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4043 - val_loss: 0.4336\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4357\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4036 - val_loss: 0.4360\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4035 - val_loss: 0.4346\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.4360\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4025 - val_loss: 0.4371\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4024 - val_loss: 0.4365\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4022 - val_loss: 0.4344\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4015 - val_loss: 0.4374\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4018 - val_loss: 0.4365\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4012 - val_loss: 0.4365\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4007 - val_loss: 0.4350\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4007 - val_loss: 0.4350\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4002 - val_loss: 0.4374\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4002 - val_loss: 0.4370\n",
      "469/469 [==============================] - 1s 3ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4410 - val_loss: 0.4364\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4231 - val_loss: 0.4324\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4204 - val_loss: 0.4306\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4181 - val_loss: 0.4299\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4171 - val_loss: 0.4298\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4160 - val_loss: 0.4308\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4157 - val_loss: 0.4307\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4148 - val_loss: 0.4300\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4144 - val_loss: 0.4299\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4137 - val_loss: 0.4304\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4132 - val_loss: 0.4310\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4128 - val_loss: 0.4312\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4121 - val_loss: 0.4318\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4117 - val_loss: 0.4311\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4309\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4109 - val_loss: 0.4323\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4104 - val_loss: 0.4321\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4100 - val_loss: 0.4317\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4097 - val_loss: 0.4316\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4090 - val_loss: 0.4320\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4091 - val_loss: 0.4316\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4090 - val_loss: 0.4315\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4083 - val_loss: 0.4325\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4076 - val_loss: 0.4339\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4080 - val_loss: 0.4323\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.4339\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4074 - val_loss: 0.4330\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4072 - val_loss: 0.4338\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4070 - val_loss: 0.4343\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4064 - val_loss: 0.4354\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4064 - val_loss: 0.4363\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4059 - val_loss: 0.4347\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4060 - val_loss: 0.4354\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4056 - val_loss: 0.4360\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4051 - val_loss: 0.4356\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4049 - val_loss: 0.4363\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4049 - val_loss: 0.4371\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4042 - val_loss: 0.4370\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4046 - val_loss: 0.4373\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4042 - val_loss: 0.4382\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4036 - val_loss: 0.4383\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4037 - val_loss: 0.4366\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4033 - val_loss: 0.4382\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4031 - val_loss: 0.4379\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.4399\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4026 - val_loss: 0.4387\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4026 - val_loss: 0.4385\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4020 - val_loss: 0.4391\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4019 - val_loss: 0.4390\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4020 - val_loss: 0.4397\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "90\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4359 - val_loss: 0.4187\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4273 - val_loss: 0.4164\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4248 - val_loss: 0.4148\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4229 - val_loss: 0.4147\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4217 - val_loss: 0.4133\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4206 - val_loss: 0.4136\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4198 - val_loss: 0.4126\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4191 - val_loss: 0.4136\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4185 - val_loss: 0.4127\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4177 - val_loss: 0.4145\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4172 - val_loss: 0.4131\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4171 - val_loss: 0.4135\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4161 - val_loss: 0.4137\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4159 - val_loss: 0.4120\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4157 - val_loss: 0.4117\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4150 - val_loss: 0.4120\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4147 - val_loss: 0.4131\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4145 - val_loss: 0.4138\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4141 - val_loss: 0.4133\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4139 - val_loss: 0.4139\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4134 - val_loss: 0.4125\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4130 - val_loss: 0.4130\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4128 - val_loss: 0.4136\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4125 - val_loss: 0.4140\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4122 - val_loss: 0.4140\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4120 - val_loss: 0.4149\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4118 - val_loss: 0.4136\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4114 - val_loss: 0.4149\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4111 - val_loss: 0.4136\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4106 - val_loss: 0.4145\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4105 - val_loss: 0.4138\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4099 - val_loss: 0.4148\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4094 - val_loss: 0.4154\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4093 - val_loss: 0.4157\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4090 - val_loss: 0.4164\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4090 - val_loss: 0.4145\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4085 - val_loss: 0.4149\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4084 - val_loss: 0.4155\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4081 - val_loss: 0.4163\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4078 - val_loss: 0.4169\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4076 - val_loss: 0.4165\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4073 - val_loss: 0.4159\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4069 - val_loss: 0.4175\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4071 - val_loss: 0.4170\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4062 - val_loss: 0.4174\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4062 - val_loss: 0.4159\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4064 - val_loss: 0.4177\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4173\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4054 - val_loss: 0.4182\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4055 - val_loss: 0.4179\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4425 - val_loss: 0.4209\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4277 - val_loss: 0.4163\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4252 - val_loss: 0.4147\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4239 - val_loss: 0.4137\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4225 - val_loss: 0.4127\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4219 - val_loss: 0.4127\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4211 - val_loss: 0.4131\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4205 - val_loss: 0.4135\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4198 - val_loss: 0.4126\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4189 - val_loss: 0.4138\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4181 - val_loss: 0.4146\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4172 - val_loss: 0.4137\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4167 - val_loss: 0.4136\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4160 - val_loss: 0.4146\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4150 - val_loss: 0.4157\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4147 - val_loss: 0.4157\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4140 - val_loss: 0.4160\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4132 - val_loss: 0.4155\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4124 - val_loss: 0.4163\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4120 - val_loss: 0.4165\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4119 - val_loss: 0.4144\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4113 - val_loss: 0.4154\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4108 - val_loss: 0.4182\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4103 - val_loss: 0.4185\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4099 - val_loss: 0.4190\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4094 - val_loss: 0.4177\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4089 - val_loss: 0.4195\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4090 - val_loss: 0.4205\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4081 - val_loss: 0.4193\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4078 - val_loss: 0.4210\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4076 - val_loss: 0.4191\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4070 - val_loss: 0.4195\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4071 - val_loss: 0.4198\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4064 - val_loss: 0.4210\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4062 - val_loss: 0.4226\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4203\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4055 - val_loss: 0.4214\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4056 - val_loss: 0.4212\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4051 - val_loss: 0.4209\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4047 - val_loss: 0.4227\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4043 - val_loss: 0.4229\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4044 - val_loss: 0.4224\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4222\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4036 - val_loss: 0.4218\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4031 - val_loss: 0.4232\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4032 - val_loss: 0.4218\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4026 - val_loss: 0.4245\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4024 - val_loss: 0.4217\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4023 - val_loss: 0.4246\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4023 - val_loss: 0.4224\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4438 - val_loss: 0.3859\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4337 - val_loss: 0.3844\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4317 - val_loss: 0.3852\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4304 - val_loss: 0.3871\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4293 - val_loss: 0.3843\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4282 - val_loss: 0.3846\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4275 - val_loss: 0.3843\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4267 - val_loss: 0.3840\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4260 - val_loss: 0.3843\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4256 - val_loss: 0.3856\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4252 - val_loss: 0.3844\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4244 - val_loss: 0.3853\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4237 - val_loss: 0.3850\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4233 - val_loss: 0.3840\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4228 - val_loss: 0.3851\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4220 - val_loss: 0.3846\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4218 - val_loss: 0.3844\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4210 - val_loss: 0.3859\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4211 - val_loss: 0.3851\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4205 - val_loss: 0.3848\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4197 - val_loss: 0.3868\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4193 - val_loss: 0.3865\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4191 - val_loss: 0.3860\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4186 - val_loss: 0.3872\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4179 - val_loss: 0.3882\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4172 - val_loss: 0.3860\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4171 - val_loss: 0.3860\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4165 - val_loss: 0.3889\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4166 - val_loss: 0.3872\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4158 - val_loss: 0.3889\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4153 - val_loss: 0.3878\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4153 - val_loss: 0.3862\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4150 - val_loss: 0.3880\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4150 - val_loss: 0.3895\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4140 - val_loss: 0.3869\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4149 - val_loss: 0.3882\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4135 - val_loss: 0.3901\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4133 - val_loss: 0.3923\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4128 - val_loss: 0.3907\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4127 - val_loss: 0.3945\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4124 - val_loss: 0.3941\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4123 - val_loss: 0.3947\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4120 - val_loss: 0.3921\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4118 - val_loss: 0.3962\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4118 - val_loss: 0.3945\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4114 - val_loss: 0.3954\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4106 - val_loss: 0.3909\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4107 - val_loss: 0.3958\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4103 - val_loss: 0.3954\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4105 - val_loss: 0.3990\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4341 - val_loss: 0.4380\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4229 - val_loss: 0.4358\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4206 - val_loss: 0.4342\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4196 - val_loss: 0.4319\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4186 - val_loss: 0.4319\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4175 - val_loss: 0.4314\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4168 - val_loss: 0.4298\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4161 - val_loss: 0.4304\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4156 - val_loss: 0.4295\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4154 - val_loss: 0.4292\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4149 - val_loss: 0.4290\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4142 - val_loss: 0.4292\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4139 - val_loss: 0.4295\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4136 - val_loss: 0.4299\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4130 - val_loss: 0.4278\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4125 - val_loss: 0.4301\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4125 - val_loss: 0.4294\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4122 - val_loss: 0.4280\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4117 - val_loss: 0.4300\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4111 - val_loss: 0.4288\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4112 - val_loss: 0.4293\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4104 - val_loss: 0.4303\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4106 - val_loss: 0.4295\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4101 - val_loss: 0.4290\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4095 - val_loss: 0.4285\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4090 - val_loss: 0.4317\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4090 - val_loss: 0.4296\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4088 - val_loss: 0.4287\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4085 - val_loss: 0.4297\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4081 - val_loss: 0.4290\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4081 - val_loss: 0.4303\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4074 - val_loss: 0.4295\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4074 - val_loss: 0.4295\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4072 - val_loss: 0.4295\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.4289\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4062 - val_loss: 0.4319\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4059 - val_loss: 0.4300\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4058 - val_loss: 0.4309\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4051 - val_loss: 0.4306\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4049 - val_loss: 0.4325\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4053 - val_loss: 0.4321\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4043 - val_loss: 0.4326\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4044 - val_loss: 0.4333\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4039 - val_loss: 0.4323\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4038 - val_loss: 0.4316\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4038 - val_loss: 0.4325\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.4327\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4029 - val_loss: 0.4339\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4030 - val_loss: 0.4332\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4023 - val_loss: 0.4344\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 3s 4ms/step - loss: 0.4275 - val_loss: 0.4746\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4141 - val_loss: 0.4734\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4119 - val_loss: 0.4721\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4101 - val_loss: 0.4717\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4086 - val_loss: 0.4709\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4073 - val_loss: 0.4706\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4067 - val_loss: 0.4707\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4060 - val_loss: 0.4712\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4052 - val_loss: 0.4701\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4045 - val_loss: 0.4701\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4039 - val_loss: 0.4706\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4031 - val_loss: 0.4700\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4027 - val_loss: 0.4707\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4022 - val_loss: 0.4704\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4016 - val_loss: 0.4701\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4008 - val_loss: 0.4709\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4006 - val_loss: 0.4706\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4000 - val_loss: 0.4716\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3993 - val_loss: 0.4703\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3990 - val_loss: 0.4710\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3985 - val_loss: 0.4699\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3979 - val_loss: 0.4710\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3979 - val_loss: 0.4706\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3974 - val_loss: 0.4700\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3970 - val_loss: 0.4705\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3964 - val_loss: 0.4715\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3961 - val_loss: 0.4707\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3957 - val_loss: 0.4712\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3953 - val_loss: 0.4715\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3950 - val_loss: 0.4705\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3945 - val_loss: 0.4707\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3942 - val_loss: 0.4710\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3939 - val_loss: 0.4708\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3937 - val_loss: 0.4706\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3934 - val_loss: 0.4709\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3931 - val_loss: 0.4716\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3925 - val_loss: 0.4712\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3925 - val_loss: 0.4712\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3922 - val_loss: 0.4710\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3916 - val_loss: 0.4723\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3914 - val_loss: 0.4719\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3913 - val_loss: 0.4729\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3907 - val_loss: 0.4723\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3907 - val_loss: 0.4742\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3900 - val_loss: 0.4727\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3901 - val_loss: 0.4735\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3900 - val_loss: 0.4737\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3894 - val_loss: 0.4733\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3894 - val_loss: 0.4733\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3890 - val_loss: 0.4734\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4358 - val_loss: 0.4162\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4272 - val_loss: 0.4140\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4247 - val_loss: 0.4126\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4233 - val_loss: 0.4125\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4222 - val_loss: 0.4117\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4210 - val_loss: 0.4157\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4204 - val_loss: 0.4130\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4194 - val_loss: 0.4123\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4185 - val_loss: 0.4115\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4183 - val_loss: 0.4124\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4172 - val_loss: 0.4126\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4170 - val_loss: 0.4119\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4160 - val_loss: 0.4129\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4154 - val_loss: 0.4135\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4155 - val_loss: 0.4137\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4153 - val_loss: 0.4127\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4142 - val_loss: 0.4122\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4138 - val_loss: 0.4135\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4137 - val_loss: 0.4142\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4135 - val_loss: 0.4129\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4128 - val_loss: 0.4145\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4128 - val_loss: 0.4148\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4120 - val_loss: 0.4140\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4123 - val_loss: 0.4155\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4152\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4116 - val_loss: 0.4147\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4166\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4168\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4149\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4149\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4100 - val_loss: 0.4150\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4098 - val_loss: 0.4159\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4098 - val_loss: 0.4150\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4092 - val_loss: 0.4150\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4088 - val_loss: 0.4172\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4084 - val_loss: 0.4210\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4085 - val_loss: 0.4164\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4085 - val_loss: 0.4173\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4082 - val_loss: 0.4156\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4072 - val_loss: 0.4171\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4074 - val_loss: 0.4173\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4074 - val_loss: 0.4167\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4071 - val_loss: 0.4172\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4066 - val_loss: 0.4201\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4070 - val_loss: 0.4189\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4059 - val_loss: 0.4188\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4063 - val_loss: 0.4189\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4061 - val_loss: 0.4187\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4058 - val_loss: 0.4196\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4054 - val_loss: 0.4198\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4345 - val_loss: 0.4373\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4209 - val_loss: 0.4348\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4183 - val_loss: 0.4353\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4171 - val_loss: 0.4335\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4160 - val_loss: 0.4335\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4152 - val_loss: 0.4333\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4145 - val_loss: 0.4334\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4140 - val_loss: 0.4332\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4133 - val_loss: 0.4322\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4134 - val_loss: 0.4331\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4126 - val_loss: 0.4335\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4120 - val_loss: 0.4345\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4118 - val_loss: 0.4332\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4336\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4112 - val_loss: 0.4344\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4343\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4106 - val_loss: 0.4348\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4101 - val_loss: 0.4338\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4097 - val_loss: 0.4365\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4098 - val_loss: 0.4357\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4095 - val_loss: 0.4355\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4089 - val_loss: 0.4361\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4081 - val_loss: 0.4370\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4082 - val_loss: 0.4358\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4076 - val_loss: 0.4366\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4071 - val_loss: 0.4369\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4072 - val_loss: 0.4367\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4070 - val_loss: 0.4368\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.4386\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4062 - val_loss: 0.4366\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4356\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4055 - val_loss: 0.4374\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4051 - val_loss: 0.4362\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4053 - val_loss: 0.4374\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4050 - val_loss: 0.4365\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4049 - val_loss: 0.4365\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4040 - val_loss: 0.4371\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4040 - val_loss: 0.4377\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4041 - val_loss: 0.4368\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4037 - val_loss: 0.4365\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4034 - val_loss: 0.4402\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.4380\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4030 - val_loss: 0.4374\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4023 - val_loss: 0.4366\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4023 - val_loss: 0.4392\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4019 - val_loss: 0.4388\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4019 - val_loss: 0.4356\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4016 - val_loss: 0.4393\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4012 - val_loss: 0.4420\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4011 - val_loss: 0.4413\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4397 - val_loss: 0.4067\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4299 - val_loss: 0.4041\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4281 - val_loss: 0.4023\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4267 - val_loss: 0.4020\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4254 - val_loss: 0.4005\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4245 - val_loss: 0.3999\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4236 - val_loss: 0.4001\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4230 - val_loss: 0.4002\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4223 - val_loss: 0.3997\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4218 - val_loss: 0.3992\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4211 - val_loss: 0.3999\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4207 - val_loss: 0.3994\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4200 - val_loss: 0.3995\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4193 - val_loss: 0.3995\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4192 - val_loss: 0.3996\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4182 - val_loss: 0.4011\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4183 - val_loss: 0.4005\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4175 - val_loss: 0.4005\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4169 - val_loss: 0.3994\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4161 - val_loss: 0.3995\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4159 - val_loss: 0.4014\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4156 - val_loss: 0.4009\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4152 - val_loss: 0.4004\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4142 - val_loss: 0.4025\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4140 - val_loss: 0.4017\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4141 - val_loss: 0.4029\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4132 - val_loss: 0.4038\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4132 - val_loss: 0.4027\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4126 - val_loss: 0.4034\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4126 - val_loss: 0.4027\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4122 - val_loss: 0.4028\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4030\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4110 - val_loss: 0.4048\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4108 - val_loss: 0.4057\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4031\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4103 - val_loss: 0.4047\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4102 - val_loss: 0.4033\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4095 - val_loss: 0.4043\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4094 - val_loss: 0.4050\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4092 - val_loss: 0.4041\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4086 - val_loss: 0.4050\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4084 - val_loss: 0.4046\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4087 - val_loss: 0.4056\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4081 - val_loss: 0.4064\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.4061\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4069 - val_loss: 0.4064\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4072 - val_loss: 0.4064\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4067 - val_loss: 0.4072\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4068 - val_loss: 0.4059\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4064 - val_loss: 0.4057\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.4358 - val_loss: 0.4179\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4279 - val_loss: 0.4158\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4253 - val_loss: 0.4141\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4237 - val_loss: 0.4145\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4224 - val_loss: 0.4144\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4213 - val_loss: 0.4134\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4208 - val_loss: 0.4141\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4201 - val_loss: 0.4137\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4192 - val_loss: 0.4151\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4191 - val_loss: 0.4141\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4184 - val_loss: 0.4147\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4178 - val_loss: 0.4147\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4173 - val_loss: 0.4143\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4168 - val_loss: 0.4146\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4160 - val_loss: 0.4149\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4158 - val_loss: 0.4139\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4158 - val_loss: 0.4143\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4150 - val_loss: 0.4144\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4146 - val_loss: 0.4141\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4142 - val_loss: 0.4154\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4138 - val_loss: 0.4151\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4135 - val_loss: 0.4145\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4129 - val_loss: 0.4146\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4125 - val_loss: 0.4160\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4124 - val_loss: 0.4153\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4121 - val_loss: 0.4144\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4114 - val_loss: 0.4159\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4111 - val_loss: 0.4162\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4158\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4104 - val_loss: 0.4158\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4099 - val_loss: 0.4155\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4093 - val_loss: 0.4169\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4095 - val_loss: 0.4165\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4086 - val_loss: 0.4189\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4088 - val_loss: 0.4175\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4087 - val_loss: 0.4164\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4083 - val_loss: 0.4173\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4075 - val_loss: 0.4172\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4081 - val_loss: 0.4174\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4073 - val_loss: 0.4175\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4067 - val_loss: 0.4172\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4068 - val_loss: 0.4195\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.4182\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4063 - val_loss: 0.4201\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4061 - val_loss: 0.4182\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4183\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4055 - val_loss: 0.4197\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4048 - val_loss: 0.4195\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4046 - val_loss: 0.4190\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4047 - val_loss: 0.4190\n",
      "469/469 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Rerun model 100 times\n",
    "num_reruns = 100\n",
    "alphas = []\n",
    "\n",
    "np.random.seed(519)\n",
    "seeds = np.random.randint(9999, size=num_reruns)\n",
    "\n",
    "for i in range(num_reruns):\n",
    "    model_fit = fitting_returns_data(\n",
    "        'ff6_factors_19630701_20230131.csv',\n",
    "        io_day_1_lag,\n",
    "        model_feed_forward,\n",
    "        seed = seeds[i],\n",
    "        print_summary = False)[2]\n",
    "    alphas.append(model_fit.params[0])\n",
    "    if i%10 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "k4Yfo9e5Iqze",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "k4Yfo9e5Iqze",
    "outputId": "51b81cb7-4b39-4874-c11d-3a2396fe29f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest return if we ignore robustness: 0.13485969142097237\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFoklEQVR4nO3deVwV9f7H8fcBBFxYXFAgCfd9K0pz17RwydyyxEo0s25XK1NbbNPSwupqda+m9bsqdrM0KzVLvZopVmpeXLKsSA1FU9wSELwgwvf3hw/O7cgS4IFzcF7Px2MedWa+M/OZLyPnzcx3zrEZY4wAAAAsxMPVBQAAAJQ3AhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhAAALAcAhDcQr169TRq1ChXl3HVe+2119SgQQN5enqqXbt2ri6nWEaNGqV69eq5ugy35e79ExsbK5vNpkOHDpV43WnTpslmszm1ns2bN8tms2nz5s2lXvejjz5yak1wDQIQnC7vF158fHyBy3v06KFWrVpd8X7WrFmjadOmXfF2rGL9+vV64okn1LlzZy1atEgvv/xyoW1HjRolm81W4LRu3bpyrLr4evToUWjNP//8s6vLc7m8/mncuHGByzds2GDvr4r8Bn/nnXfKZrPpySefdHUpcHNeri4AkKSEhAR5eJQsj69Zs0Zz584lBBXTl19+KQ8PDy1YsEDe3t5/2t7Hx0f//Oc/881v27ZtWZTnFHXr1lVMTEy++aGhoS6oxv34+vrqwIED2rFjh9q3b++wbMmSJfL19VVmZqaLqrtyaWlpWr16terVq6cPPvhAM2fOdPoVJFw9CEBwCz4+Pq4uocQyMjJUtWpVV5dRbCdPnlTlypWLFX4kycvLS/fcc08ZV+VcAQEBZVKzMUaZmZmqXLmy07f9ZzIzM+Xt7V3iPxAK0rBhQ128eFEffPCBQwDKzMzUihUr1L9/f3388cdXvB9X+fjjj5WTk6OFCxfq5ptv1pYtW9S9e3dXlwU3xS0wuIXLxwBlZ2frhRdeUOPGjeXr66uaNWuqS5cu2rBhg6RLt2jmzp0rSQ63OvJkZGRo0qRJCgsLk4+Pj5o2baq//e1vMsY47Pe///2vHnnkEdWqVUt+fn66/fbb9dtvv8lmszlcWcobi/Djjz9qxIgRql69urp06SJJ2rt3r0aNGqUGDRrI19dXwcHBuu+++3TmzBmHfeVt45dfftE999yjgIAABQUF6bnnnpMxRkeOHNHAgQPl7++v4OBgzZo1q1h9d/HiRU2fPl0NGzaUj4+P6tWrp6efflpZWVn2NjabTYsWLVJGRoa9r2JjY4u1/cLk5ubqjTfeUMuWLeXr66s6derowQcf1NmzZ/O1Xbt2rbp27aqqVavKz89P/fv31759+/K1W7lypVq1aiVfX1+1atVKK1asuKIaL1ecvpIunY+33Xab/v3vf+uGG25Q5cqV9fbbb2vIkCG6/vrrHdoOGDBANptNn376qX3et99+K5vNprVr10qSfv/9d02ePFmtW7dWtWrV5O/vr759++q7775z2FbeGJOlS5fq2Wef1TXXXKMqVaooLS3Naf0TFRWlZcuWKTc31z5v9erVOn/+vO68884C19m9e7f69u0rf39/VatWTb169dL27dvztdu3b59uvvlmVa5cWXXr1tWMGTMc9vNHxT0nSmLJkiW65ZZb1LNnTzVv3lxLliwp1np5t+V37typTp06qXLlyqpfv77mz59fYPvc3Fy99NJLqlu3rnx9fdWrVy8dOHDAoc1XX32lYcOG6dprr5WPj4/CwsL02GOP6b///a9Du+TkZI0ePVp169aVj4+PQkJCNHDgwFKNmULJcAUIZSY1NVWnT5/ONz87O/tP1502bZpiYmJ0//33q3379kpLS1N8fLx27dqlW265RQ8++KCOHTumDRs26F//+pfDusYY3X777dq0aZPGjBmjdu3a6d///rcef/xx/fbbb3r99dftbUeNGqUPP/xQ9957r2666SbFxcWpf//+hdY1bNgwNW7cWC+//LI9TG3YsEG//vqrRo8ereDgYO3bt0/vvPOO9u3bp+3bt+e7BH/XXXepefPmmjlzpj7//HPNmDFDNWrU0Ntvv62bb75Zr7zyipYsWaLJkyfrxhtvVLdu3Yrsq/vvv1+LFy/WHXfcoUmTJunbb79VTEyMfvrpJ/sb5L/+9S+988472rFjh/22VqdOnf7053D5z69SpUoKCAiQJD344IOKjY3V6NGj9cgjjygxMVFz5szR7t279c0336hSpUr2fUdHRysyMlKvvPKKzp8/r3nz5qlLly7avXu3fQDv+vXrNXToULVo0UIxMTE6c+aM/Y2huHJycvLV7Ovrq2rVqhW7r/IkJCQoKipKDz74oMaOHaumTZvKGKNVq1YpLS1N/v7+Msbom2++kYeHh7766ivdfvvtki69+Xl4eKhz586SpF9//VUrV67UsGHDVL9+fZ04cUJvv/22unfvrh9//DHfLbrp06fL29tbkydPVlZWlry9vZ3SP5I0YsQITZs2TZs3b9bNN98sSXr//ffVq1cv1a5dO1/7ffv2qWvXrvL399cTTzyhSpUq6e2331aPHj0UFxenDh06SLr0Rt6zZ09dvHhRTz31lKpWrap33nmnwKtmxT0nSuLYsWPatGmTFi9eLOlS0Hv99dc1Z86cYl31PHv2rPr166c777xTUVFR+vDDD/XQQw/J29tb9913n0PbmTNnysPDQ5MnT1ZqaqpeffVV3X333fr222/tbZYvX67z58/roYceUs2aNbVjxw794x//0NGjR7V8+XJ7u6FDh2rfvn16+OGHVa9ePZ08eVIbNmxQUlKSWw9uvyoYwMkWLVpkJBU5tWzZ0mGd8PBwEx0dbX/dtm1b079//yL3M27cOFPQKbxy5UojycyYMcNh/h133GFsNps5cOCAMcaYnTt3GklmwoQJDu1GjRplJJmpU6fa502dOtVIMlFRUfn2d/78+XzzPvjgAyPJbNmyJd82HnjgAfu8ixcvmrp16xqbzWZmzpxpn3/27FlTuXJlhz4pyJ49e4wkc//99zvMnzx5spFkvvzyS/u86OhoU7Vq1SK398e2Bf3cunfvbowx5quvvjKSzJIlSxzWW7duncP8c+fOmcDAQDN27FiHdsnJySYgIMBhfrt27UxISIhJSUmxz1u/fr2RZMLDw/+05u7duxdYc14flqSvwsPDjSSzbt06h7b/+c9/jCSzZs0aY4wxe/fuNZLMsGHDTIcOHeztbr/9dnPdddfZX2dmZpqcnByHbSUmJhofHx/z4osv2udt2rTJSDINGjTId145o3/y/t3dcMMNZsyYMcaYS+eat7e3Wbx4sX3/y5cvt683aNAg4+3tbQ4ePGifd+zYMePn52e6detmnzdhwgQjyXz77bf2eSdPnjQBAQFGkklMTDTGlOycyPs3Uxx/+9vfTOXKlU1aWpoxxphffvnFSDIrVqxwaJd3jJs2bXLoG0lm1qxZ9nlZWVmmXbt2pnbt2ubChQsO6zZv3txkZWXZ27755ptGkvn+++/t8wr6vRATE2NsNps5fPiwMeZS30syr732WrGOEc7FLTCUmblz52rDhg35pjZt2vzpuoGBgdq3b5/2799f4v2uWbNGnp6eeuSRRxzmT5o0ScYY+22JvKeZ/vrXvzq0e/jhhwvd9l/+8pd88/74F25mZqZOnz6tm266SZK0a9eufO3vv/9++/97enrqhhtukDFGY8aMsc8PDAxU06ZN9euvvxZai3TpWCVp4sSJDvMnTZokSfr888+LXL8ovr6++X52ebflli9froCAAN1yyy06ffq0fYqIiFC1atW0adMmSZeujqWkpCgqKsqhnaenpzp06GBvd/z4ce3Zs0fR0dH2K0ySdMstt6hFixbFrrlevXr5an7iiScklbyv6tevr8jISId51113napVq6YtW7ZIunSlp27duho5cqR27dql8+fPyxijr7/+Wl27drWv5+PjYx/Dk5OTozNnzqhatWpq2rRpgedIdHS0w3nlrP7JM2LECH3yySe6cOGCPvroI3l6emrw4MH52uXk5Gj9+vUaNGiQGjRoYJ8fEhKiESNG6Ouvv7bfnluzZo1uuukmh7FFQUFBuvvuux22WdxzoqSWLFmi/v37y8/PT5LUuHFjRUREFPs2mJeXlx588EH7a29vbz344IM6efKkdu7c6dB29OjRDleV8n7Wf/z3+sefX0ZGhk6fPq1OnTrJGKPdu3fb23h7e2vz5s0F3jpG2eIWGMpM+/btdcMNN+SbX7169QJvjf3Riy++qIEDB6pJkyZq1aqV+vTpo3vvvbdY4enw4cMKDQ21/yLM07x5c/vyvP96eHiofv36Du0aNWpU6LYvbytdGt/xwgsvaOnSpTp58qTDstTU1Hztr732WofXAQEB8vX1Va1atfLNv3wc0eXyjuHymoODgxUYGGg/1tLw9PRU7969C1y2f/9+paamFnjLRJK9H/ICbN6tlsv5+/tL+t/PpKBHtAsLCQWpWrVqoTWXtK8K+ll7enqqY8eO+uqrryRdCkBdu3ZVly5dlJOTo+3bt6tOnTr6/fffHQJQbm6u3nzzTb311ltKTExUTk6OfVnNmjXz7efyfTurf/IMHz5ckydP1tq1a7VkyRLddttt+f69SNKpU6d0/vx5NW3aNN+y5s2bKzc3V0eOHFHLli11+PBh++2wy+v7o+KeEyXx008/affu3Ro5cqTDWJwePXpo7ty59luWRQkNDc33UEOTJk0kSYcOHbL/USPl/zdcvXp1SXIIMUlJSXr++ef16aef5gs3eb8XfHx89Morr2jSpEmqU6eObrrpJt12220aOXKkgoODi3v4KCUCENxSt27ddPDgQa1atUrr16/XP//5T73++uuaP3++wxWU8lbQeIY777xTW7du1eOPP6527dqpWrVqys3NVZ8+fQocAOrp6VmseZLyDdouTHk/6pubm6vatWsX+td1UFCQvZ10acxHQb/QvbzK/1dQcfuqsCe+unTpopdeekmZmZn66quv9MwzzygwMFCtWrXSV199pTp16kiSQwB6+eWX9dxzz+m+++7T9OnTVaNGDXl4eGjChAkFniNl/bRZSEiIevTooVmzZumbb74p1ye/yuKceO+99yRJjz32mB577LF8yz/++GONHj26xNstzJ/9e83JydEtt9yi33//XU8++aSaNWumqlWr6rffftOoUaMcfuYTJkzQgAEDtHLlSv373//Wc889p5iYGH355Ze67rrrnFYz8iMAwW3VqFFDo0eP1ujRo5Wenq5u3bpp2rRp9gBU2BtZeHi4vvjiC507d87hr9q8D8MLDw+3/zc3N1eJiYkOf1lf/jRHUc6ePauNGzfqhRde0PPPP2+fX5pbd6WRdwz79++3X+GSpBMnTiglJcV+rM7WsGFDffHFF+rcuXORb9YNGzaUJNWuXbvQKzPS/34mBfVbQkLCFVb7v304o6+6du2qCxcu6IMPPtBvv/1mDzrdunWzB6AmTZrYg5AkffTRR+rZs6cWLFjgsK2UlJR8V/4Kq11ybv+MGDFC999/vwIDA9WvX78C2wQFBalKlSoF7uPnn3+Wh4eHwsLC7DUWp77inhPFZYzR+++/r549e+a7nS1dGlC+ZMmSPw1Ax44dy/fRFr/88osklXgw8vfff69ffvlFixcv1siRI+3z855ivVzDhg01adIkTZo0Sfv371e7du00a9Yse7BD2WAMENzS5bd+qlWrpkaNGjk8rpz3iyolJcWhbb9+/ZSTk6M5c+Y4zH/99ddls9nUt29fSbKP73jrrbcc2v3jH/8odp15fwlefqXmjTfeKPY2rkTeG9fl+5s9e7YkFflE25W48847lZOTo+nTp+dbdvHiRfvPJDIyUv7+/nr55ZcLfPrv1KlTki5dkWjXrp0WL17scNtww4YN+vHHH51Ss7P6qkOHDqpUqZJeeeUV1ahRQy1btpR0KRht375dcXFxDld/pEvnyeXnyPLly/Xbb78Va59l0T933HGHpk6dqrfeeqvQp6Q8PT116623atWqVQ6PZZ84cULvv/++unTpYr+11K9fP23fvl07duywtzt16lS+q4TFPSeK65tvvtGhQ4c0evRo3XHHHfmmu+66S5s2bdKxY8eK3M7Fixf19ttv219fuHBBb7/9toKCghQREVGimgr6vWCM0ZtvvunQ7vz58/k+eLJhw4by8/PL99EMcD6uAMEttWjRQj169FBERIRq1Kih+Ph4ffTRRxo/fry9Td4vpUceeUSRkZHy9PTU8OHDNWDAAPXs2VPPPPOMDh06pLZt22r9+vVatWqVJkyYYP8LNCIiQkOHDtUbb7yhM2fO2B+Dz/urrzi3Svz9/dWtWze9+uqrys7O1jXXXKP169crMTGxDHolv7Zt2yo6OlrvvPOOUlJS1L17d+3YsUOLFy/WoEGD1LNnzzLZb/fu3fXggw8qJiZGe/bs0a233qpKlSpp//79Wr58ud58803dcccd8vf317x583Tvvffq+uuv1/DhwxUUFKSkpCR9/vnn6ty5sz2oxsTEqH///urSpYvuu+8+/f777/rHP/6hli1bKj09/YprdlZfValSRREREdq+fbv9M4CkS1eAMjIylJGRkS8A3XbbbXrxxRc1evRoderUSd9//72WLFniMLD4zzi7fwICAor1KeozZszQhg0b1KVLF/31r3+Vl5eX3n77bWVlZenVV1+1t3viiSf0r3/9S3369NGjjz5qfww+PDxce/futbcryTlRHEuWLJGnp2ehAfb222/XM888o6VLl+YbAP9HoaGheuWVV3To0CE1adJEy5Yt0549e/TOO+/YP9KhuJo1a6aGDRtq8uTJ+u233+Tv76+PP/4431igX375Rb169dKdd96pFi1ayMvLSytWrNCJEyc0fPjwEu0TpeCip89wFct7DP4///lPgcv/+Dhunssfg58xY4Zp3769CQwMNJUrVzbNmjUzL730kv1xVGMuPUL+8MMPm6CgIGOz2Rwelz137px57LHHTGhoqKlUqZJp3Lixee2110xubq7DfjMyMsy4ceNMjRo1TLVq1cygQYNMQkKCkeTwWHre47inTp3KdzxHjx41gwcPNoGBgSYgIMAMGzbMHDt2rNBH6S/fRmGPpxfUTwXJzs42L7zwgqlfv76pVKmSCQsLM1OmTDGZmZnF2k9Bitv2nXfeMREREaZy5crGz8/PtG7d2jzxxBPm2LFjDu02bdpkIiMjTUBAgPH19TUNGzY0o0aNMvHx8Q7tPv74Y9O8eXPj4+NjWrRoYT755BMTHR1d4se8C1PcvgoPDy/yYxgef/xxI8m88sorDvMbNWpkJDk8Mm7MpcfgJ02aZEJCQkzlypVN586dzbZt20z37t3tHy1gjCnwMfQ/Kuv+KWz/u3btMpGRkaZatWqmSpUqpmfPnmbr1q351t+7d6/p3r278fX1Nddcc42ZPn26WbBggcNj8H/c15+dE3/2GPyFCxdMzZo1TdeuXYs8rvr169s/lqCwx+Bbtmxp4uPjTceOHY2vr68JDw83c+bMKVb/JCYmGklm0aJF9nk//vij6d27t6lWrZqpVauWGTt2rPnuu+8c2p0+fdqMGzfONGvWzFStWtUEBASYDh06mA8//LDI44Fz2Iwp5ihLwCL27Nmj6667Tu+9916+R3gBXH169Oih06dP64cffnB1KShHjAGCpV3+sfTSpTEiHh4ef/oJzACAiosxQLC0V199VTt37lTPnj3l5eWltWvXau3atXrggQfsT7cAAK4+BCBYWqdOnbRhwwZNnz5d6enpuvbaazVt2jQ988wzri4NAFCGGAMEAAAshzFAAADAcghAAADAchgDVIDc3FwdO3ZMfn5+5f4dSwAAoHSMMTp37pxCQ0Pl4VH0NR4CUAGOHTvGE0AAAFRQR44cUd26dYtsQwAqQN4XaB45csT+PTcAAMC9paWlKSwszOGLsAtDACpA3m0vf39/AhAAABVMcYavMAgaAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYDgEIAABYjperCwBQsQ0Y4OoKSm71aldXAMDVuAIEAAAshwAEAAAshwAEAAAshwAEAAAshwAEAAAshwAEAAAshwAEAAAshwAEAAAshwAEAAAshwAEAAAshwAEAAAsx6UBKCYmRjfeeKP8/PxUu3ZtDRo0SAkJCQ5tMjMzNW7cONWsWVPVqlXT0KFDdeLEiSK3a4zR888/r5CQEFWuXFm9e/fW/v37y/JQAABABeLSABQXF6dx48Zp+/bt2rBhg7Kzs3XrrbcqIyPD3uaxxx7T6tWrtXz5csXFxenYsWMaMmRIkdt99dVX9fe//13z58/Xt99+q6pVqyoyMlKZmZllfUgAAKACsBljjKuLyHPq1CnVrl1bcXFx6tatm1JTUxUUFKT3339fd9xxhyTp559/VvPmzbVt2zbddNNN+bZhjFFoaKgmTZqkyZMnS5JSU1NVp04dxcbGavjw4X9aR1pamgICApSamip/f3/nHiRwleHb4AG4i5K8f7vVGKDU1FRJUo0aNSRJO3fuVHZ2tnr37m1v06xZM1177bXatm1bgdtITExUcnKywzoBAQHq0KFDoetkZWUpLS3NYQIAAFcvtwlAubm5mjBhgjp37qxWrVpJkpKTk+Xt7a3AwECHtnXq1FFycnKB28mbX6dOnWKvExMTo4CAAPsUFhZ2hUcDAADcmdsEoHHjxumHH37Q0qVLy33fU6ZMUWpqqn06cuRIudcAAADKj1sEoPHjx+uzzz7Tpk2bVLduXfv84OBgXbhwQSkpKQ7tT5w4oeDg4AK3lTf/8ifFilrHx8dH/v7+DhMAALh6uTQAGWM0fvx4rVixQl9++aXq16/vsDwiIkKVKlXSxo0b7fMSEhKUlJSkjh07FrjN+vXrKzg42GGdtLQ0ffvtt4WuAwAArMWlAWjcuHF677339P7778vPz0/JyclKTk7Wf//7X0mXBi+PGTNGEydO1KZNm7Rz506NHj1aHTt2dHgCrFmzZlqxYoUkyWazacKECZoxY4Y+/fRTff/99xo5cqRCQ0M1aNAgVxwmAABwM16u3Pm8efMkST169HCYv2jRIo0aNUqS9Prrr8vDw0NDhw5VVlaWIiMj9dZbbzm0T0hIsD9BJklPPPGEMjIy9MADDyglJUVdunTRunXr5OvrW6bHAwAAKga3+hwgd8HnAAHFx+cAAXAXFfZzgAAAAMoDAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFiOS78LDICjivi1EgBQEXEFCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWI6XqwsAgPI2YICrKyi51atdXQFwdeEKEAAAsBwCEAAAsBwCEAAAsByXBqAtW7ZowIABCg0Nlc1m08qVKx2W22y2AqfXXnut0G1OmzYtX/tmzZqV8ZEAAICKxKUBKCMjQ23bttXcuXMLXH78+HGHaeHChbLZbBo6dGiR223ZsqXDel9//XVZlA8AACoolz4F1rdvX/Xt27fQ5cHBwQ6vV61apZ49e6pBgwZFbtfLyyvfugAAAHkqzBigEydO6PPPP9eYMWP+tO3+/fsVGhqqBg0a6O6771ZSUlKR7bOyspSWluYwAQCAq1eFCUCLFy+Wn5+fhgwZUmS7Dh06KDY2VuvWrdO8efOUmJiorl276ty5c4WuExMTo4CAAPsUFhbm7PIBAIAbqTABaOHChbr77rvl6+tbZLu+fftq2LBhatOmjSIjI7VmzRqlpKToww8/LHSdKVOmKDU11T4dOXLE2eUDAAA3UiE+Cfqrr75SQkKCli1bVuJ1AwMD1aRJEx04cKDQNj4+PvLx8bmSEgEAQAVSIa4ALViwQBEREWrbtm2J101PT9fBgwcVEhJSBpUBAICKyKUBKD09XXv27NGePXskSYmJidqzZ4/DoOW0tDQtX75c999/f4Hb6NWrl+bMmWN/PXnyZMXFxenQoUPaunWrBg8eLE9PT0VFRZXpsQAAgIrDpbfA4uPj1bNnT/vriRMnSpKio6MVGxsrSVq6dKmMMYUGmIMHD+r06dP210ePHlVUVJTOnDmjoKAgdenSRdu3b1dQUFDZHQgAAKhQbMYY4+oi3E1aWpoCAgKUmpoqf39/V5cDC6mI31KO8sG3wQN/riTv3xViDBAAAIAzEYAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDluDQAbdmyRQMGDFBoaKhsNptWrlzpsHzUqFGy2WwOU58+ff50u3PnzlW9evXk6+urDh06aMeOHWV0BAAAoCJyaQDKyMhQ27ZtNXfu3ELb9OnTR8ePH7dPH3zwQZHbXLZsmSZOnKipU6dq165datu2rSIjI3Xy5Elnlw8AACooL1fuvG/fvurbt2+RbXx8fBQcHFzsbc6ePVtjx47V6NGjJUnz58/X559/roULF+qpp566onoBAMDVwe3HAG3evFm1a9dW06ZN9dBDD+nMmTOFtr1w4YJ27typ3r172+d5eHiod+/e2rZtW6HrZWVlKS0tzWECAABXL5deAfozffr00ZAhQ1S/fn0dPHhQTz/9tPr27att27bJ09MzX/vTp08rJydHderUcZhfp04d/fzzz4XuJyYmRi+88ILT6wcAZxkwwNUVlNzq1a6uACicWweg4cOH2/+/devWatOmjRo2bKjNmzerV69eTtvPlClTNHHiRPvrtLQ0hYWFOW37AADAvbj9LbA/atCggWrVqqUDBw4UuLxWrVry9PTUiRMnHOafOHGiyHFEPj4+8vf3d5gAAMDVq0IFoKNHj+rMmTMKCQkpcLm3t7ciIiK0ceNG+7zc3Fxt3LhRHTt2LK8yAQCAm3NpAEpPT9eePXu0Z88eSVJiYqL27NmjpKQkpaen6/HHH9f27dt16NAhbdy4UQMHDlSjRo0UGRlp30avXr00Z84c++uJEyfq//7v/7R48WL99NNPeuihh5SRkWF/KgwAAMClY4Di4+PVs2dP++u8cTjR0dGaN2+e9u7dq8WLFyslJUWhoaG69dZbNX36dPn4+NjXOXjwoE6fPm1/fdddd+nUqVN6/vnnlZycrHbt2mndunX5BkYDAADrshljjKuLcDdpaWkKCAhQamoq44FQririkz5AYXgKDOWtJO/fFWoMEAAAgDMQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOWUKgD9+uuvzq4DAACg3JQqADVq1Eg9e/bUe++9p8zMTGfXBAAAUKZKFYB27dqlNm3aaOLEiQoODtaDDz6oHTt2OLs2AACAMlGqANSuXTu9+eabOnbsmBYuXKjjx4+rS5cuatWqlWbPnq1Tp045u04AAACnuaJB0F5eXhoyZIiWL1+uV155RQcOHNDkyZMVFhamkSNH6vjx40Wuv2XLFg0YMEChoaGy2WxauXKlfVl2draefPJJtW7dWlWrVlVoaKhGjhypY8eOFbnNadOmyWazOUzNmjW7ksMEAABXmSsKQPHx8frrX/+qkJAQzZ49W5MnT9bBgwe1YcMGHTt2TAMHDixy/YyMDLVt21Zz587Nt+z8+fPatWuXnnvuOe3atUuffPKJEhISdPvtt/9pXS1bttTx48ft09dff13qYwQAAFcfr9KsNHv2bC1atEgJCQnq16+f3n33XfXr108eHpfyVP369RUbG6t69eoVuZ2+ffuqb9++BS4LCAjQhg0bHObNmTNH7du3V1JSkq699tpCt+vl5aXg4OCSHRQAALCMUgWgefPm6b777tOoUaMUEhJSYJvatWtrwYIFV1Tc5VJTU2Wz2RQYGFhku/379ys0NFS+vr7q2LGjYmJiigxMWVlZysrKsr9OS0tzVskAAMANlSoA7d+//0/beHt7Kzo6ujSbL1BmZqaefPJJRUVFyd/fv9B2HTp0UGxsrJo2barjx4/rhRdeUNeuXfXDDz/Iz8+vwHViYmL0wgsvOK1WAADg3ko1BmjRokVavnx5vvnLly/X4sWLr7ioy2VnZ+vOO++UMUbz5s0rsm3fvn01bNgwtWnTRpGRkVqzZo1SUlL04YcfFrrOlClTlJqaap+OHDni7EMAAABupFQBKCYmRrVq1co3v3bt2nr55ZevuKg/ygs/hw8f1oYNG4q8+lOQwMBANWnSRAcOHCi0jY+Pj/z9/R0mAABw9SpVAEpKSlL9+vXzzQ8PD1dSUtIVF5UnL/zs379fX3zxhWrWrFnibaSnp+vgwYOFjlUCAADWU6oAVLt2be3duzff/O+++65EISU9PV179uzRnj17JEmJiYnas2ePkpKSlJ2drTvuuEPx8fFasmSJcnJylJycrOTkZF24cMG+jV69emnOnDn215MnT1ZcXJwOHTqkrVu3avDgwfL09FRUVFRpDhUAAFyFSjUIOioqSo888oj8/PzUrVs3SVJcXJweffRRDR8+vNjbiY+PV8+ePe2vJ06cKEmKjo7WtGnT9Omnn0q69MnTf7Rp0yb16NFDknTw4EGdPn3avuzo0aOKiorSmTNnFBQUpC5dumj79u0KCgoqzaECAICrkM0YY0q60oULF3Tvvfdq+fLl8vK6lKFyc3M1cuRIzZ8/X97e3k4vtDylpaUpICBAqampjAdCuRowwNUVAM6zerWrK4DVlOT9u1RXgLy9vbVs2TJNnz5d3333nSpXrqzWrVsrPDy8VAUDAACUp1IFoDxNmjRRkyZNnFULAABAuShVAMrJyVFsbKw2btyokydPKjc312H5l19+6ZTiAAAAykKpAtCjjz6q2NhY9e/fX61atZLNZnN2XQAAAGWmVAFo6dKl+vDDD9WvXz9n1wMAAFDmSvU5QN7e3mrUqJGzawEAACgXpQpAkyZN0ptvvqlSPEEPAADgcqW6Bfb1119r06ZNWrt2rVq2bKlKlSo5LP/kk0+cUhwAAEBZKFUACgwM1ODBg51dCwAAQLkoVQBatGiRs+sAAAAoN6UaAyRJFy9e1BdffKG3335b586dkyQdO3ZM6enpTisOAACgLJTqCtDhw4fVp08fJSUlKSsrS7fccov8/Pz0yiuvKCsrS/Pnz3d2nQAAAE5TqitAjz76qG644QadPXtWlStXts8fPHiwNm7c6LTiAAAAykKprgB99dVX2rp1a75vfa9Xr55+++03pxQGAABQVkp1BSg3N1c5OTn55h89elR+fn5XXBQAAEBZKlUAuvXWW/XGG2/YX9tsNqWnp2vq1Kl8PQYAAHB7pboFNmvWLEVGRqpFixbKzMzUiBEjtH//ftWqVUsffPCBs2sEAABwqlIFoLp16+q7777T0qVLtXfvXqWnp2vMmDG6++67HQZFAwAAuKNSBSBJ8vLy0j333OPMWgAAAMpFqQLQu+++W+TykSNHlqoYAACA8lCqAPToo486vM7Oztb58+fl7e2tKlWqEIAAAIBbK9VTYGfPnnWY0tPTlZCQoC5dujAIGgAAuL1SfxfY5Ro3bqyZM2fmuzoEAADgbpwWgKRLA6OPHTvmzE0CAAA4XanGAH366acOr40xOn78uObMmaPOnTs7pTAAAICyUqoANGjQIIfXNptNQUFBuvnmmzVr1ixn1AUAAFBmShWAcnNznV0HAABAuXHqGCAAAICKoFRXgCZOnFjstrNnzy7NLgAAAMpMqQLQ7t27tXv3bmVnZ6tp06aSpF9++UWenp66/vrr7e1sNptzqgQAAHCiUgWgAQMGyM/PT4sXL1b16tUlXfpwxNGjR6tr166aNGmSU4sEAABwplKNAZo1a5ZiYmLs4UeSqlevrhkzZpToKbAtW7ZowIABCg0Nlc1m08qVKx2WG2P0/PPPKyQkRJUrV1bv3r21f//+P93u3LlzVa9ePfn6+qpDhw7asWNHsWsCAABXv1IFoLS0NJ06dSrf/FOnTuncuXPF3k5GRobatm2ruXPnFrj81Vdf1d///nfNnz9f3377rapWrarIyEhlZmYWus1ly5Zp4sSJmjp1qnbt2qW2bdsqMjJSJ0+eLHZdAADg6laqADR48GCNHj1an3zyiY4ePaqjR4/q448/1pgxYzRkyJBib6dv376aMWOGBg8enG+ZMUZvvPGGnn32WQ0cOFBt2rTRu+++q2PHjuW7UvRHs2fP1tixYzV69Gi1aNFC8+fPV5UqVbRw4cLSHCoAALgKlSoAzZ8/X3379tWIESMUHh6u8PBwjRgxQn369NFbb73llMISExOVnJys3r172+cFBASoQ4cO2rZtW4HrXLhwQTt37nRYx8PDQ7179y50HUnKyspSWlqawwQAAK5epQpAVapU0VtvvaUzZ87Ynwj7/fff9dZbb6lq1apOKSw5OVmSVKdOHYf5derUsS+73OnTp5WTk1OidSQpJiZGAQEB9iksLOwKqwcAAO7sij4I8fjx4zp+/LgaN26sqlWryhjjrLrK1ZQpU5Sammqfjhw54uqSAABAGSpVADpz5ox69eqlJk2aqF+/fjp+/LgkacyYMU57BD44OFiSdOLECYf5J06csC+7XK1ateTp6VmidSTJx8dH/v7+DhMAALh6lSoAPfbYY6pUqZKSkpJUpUoV+/y77rpL69atc0ph9evXV3BwsDZu3Gifl5aWpm+//VYdO3YscB1vb29FREQ4rJObm6uNGzcWug4AALCeUn0Q4vr16/Xvf/9bdevWdZjfuHFjHT58uNjbSU9P14EDB+yvExMTtWfPHtWoUUPXXnutJkyYoBkzZqhx48aqX7++nnvuOYWGhjp8G32vXr00ePBgjR8/XtKlr+mIjo7WDTfcoPbt2+uNN95QRkaGRo8eXZpDBQAAV6FSBaCMjAyHKz95fv/9d/n4+BR7O/Hx8erZs6f9dd53jEVHRys2NlZPPPGEMjIy9MADDyglJUVdunTRunXr5Ovra1/n4MGDOn36tP31XXfdpVOnTun5559XcnKy2rVrp3Xr1uUbGA0AAKzLZkoxcrlfv36KiIjQ9OnT5efnp7179yo8PFzDhw9Xbm6uPvroo7KotdykpaUpICBAqampjAdCuRowwNUVAM6zerWrK4DVlOT9u1RXgF599VX16tVL8fHxunDhgp544gnt27dPv//+u7755ptSFQ0AAFBeSjUIulWrVvrll1/UpUsXDRw4UBkZGRoyZIh2796thg0bOrtGAAAApyrxFaDs7Gz16dNH8+fP1zPPPFMWNQEAAJSpEl8BqlSpkvbu3VsWtQAAAJSLUt0Cu+eee7RgwQJn1wIAAFAuSjUI+uLFi1q4cKG++OILRURE5Pv+r9mzZzulOAAAgLJQogD066+/ql69evrhhx90/fXXS5J++eUXhzY2m8151QEAAJSBEgWgxo0b6/jx49q0aZOkSx86+Pe//50PGQQAABVKicYAXf6ZiWvXrlVGRoZTCwIAAChrpRoEnacUHyINAADgciUKQDabLd8YH8b8AACAiqZEY4CMMRo1apT9C08zMzP1l7/8Jd9TYJ988onzKgQAAHCyEgWg6Ohoh9f33HOPU4sBAAAoDyUKQIsWLSqrOgAAAMrNFQ2CBgAAqIgIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHJK9G3wQEUyYICrKwCsrSL+G1y92tUVoLxwBQgAAFgOAQgAAFgOAQgAAFiO2wegevXqyWaz5ZvGjRtXYPvY2Nh8bX19fcu5agAA4M7cfhD0f/7zH+Xk5Nhf//DDD7rllls0bNiwQtfx9/dXQkKC/bXNZivTGgEAQMXi9gEoKCjI4fXMmTPVsGFDde/evdB1bDabgoODy7o0AABQQbn9LbA/unDhgt577z3dd999RV7VSU9PV3h4uMLCwjRw4EDt27evyO1mZWUpLS3NYQIAAFevChWAVq5cqZSUFI0aNarQNk2bNtXChQu1atUqvffee8rNzVWnTp109OjRQteJiYlRQECAfQoLCyuD6gEAgLuwGWOMq4sorsjISHl7e2t1CT6pKjs7W82bN1dUVJSmT59eYJusrCxlZWXZX6elpSksLEypqany9/e/4rrhGhXxQ9gAuBYfhFixpaWlKSAgoFjv324/BijP4cOH9cUXX+iTTz4p0XqVKlXSddddpwMHDhTaxsfHRz4+PldaIgAAqCAqzC2wRYsWqXbt2urfv3+J1svJydH333+vkJCQMqoMAABUNBUiAOXm5mrRokWKjo6Wl5fjRauRI0dqypQp9tcvvvii1q9fr19//VW7du3SPffco8OHD+v+++8v77IBAICbqhC3wL744gslJSXpvvvuy7csKSlJHh7/y3Fnz57V2LFjlZycrOrVqysiIkJbt25VixYtyrNkAADgxirUIOjyUpJBVHBfDIIGUFIMgq7YSvL+XSFugQEAADgTAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFiOWwegadOmyWazOUzNmjUrcp3ly5erWbNm8vX1VevWrbVmzZpyqhYAAFQUbh2AJKlly5Y6fvy4ffr6668Lbbt161ZFRUVpzJgx2r17twYNGqRBgwbphx9+KMeKAQCAu3P7AOTl5aXg4GD7VKtWrULbvvnmm+rTp48ef/xxNW/eXNOnT9f111+vOXPmlGPFAADA3bl9ANq/f79CQ0PVoEED3X333UpKSiq07bZt29S7d2+HeZGRkdq2bVuR+8jKylJaWprDBAAArl5uHYA6dOig2NhYrVu3TvPmzVNiYqK6du2qc+fOFdg+OTlZderUcZhXp04dJScnF7mfmJgYBQQE2KewsDCnHQMAAHA/bh2A+vbtq2HDhqlNmzaKjIzUmjVrlJKSog8//NCp+5kyZYpSU1Pt05EjR5y6fQAA4F68XF1ASQQGBqpJkyY6cOBAgcuDg4N14sQJh3knTpxQcHBwkdv18fGRj4+P0+oEAADuza2vAF0uPT1dBw8eVEhISIHLO3bsqI0bNzrM27Bhgzp27Fge5QEAgArCrQPQ5MmTFRcXp0OHDmnr1q0aPHiwPD09FRUVJUkaOXKkpkyZYm//6KOPat26dZo1a5Z+/vlnTZs2TfHx8Ro/fryrDgEAALght74FdvToUUVFRenMmTMKCgpSly5dtH37dgUFBUmSkpKS5OHxvwzXqVMnvf/++3r22Wf19NNPq3Hjxlq5cqVatWrlqkMAAABuyGaMMa4uwt2kpaUpICBAqamp8vf3d3U5KKUBA1xdAYCKZvVqV1eAK1GS92+3vgUGAABQFghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADActz6u8DgPvhaCQDA1YQrQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHK8XF2AFQ0Y4OoKAABXi4r4nrJ6tasr4AoQAACwIAIQAACwHAIQAACwHAIQAACwHLcOQDExMbrxxhvl5+en2rVra9CgQUpISChyndjYWNlsNofJ19e3nCoGAAAVgVsHoLi4OI0bN07bt2/Xhg0blJ2drVtvvVUZGRlFrufv76/jx4/bp8OHD5dTxQAAoCJw68fg161b5/A6NjZWtWvX1s6dO9WtW7dC17PZbAoODi7r8gAAQAXl1leALpeamipJqlGjRpHt0tPTFR4errCwMA0cOFD79u0rsn1WVpbS0tIcJgAAcPWqMAEoNzdXEyZMUOfOndWqVatC2zVt2lQLFy7UqlWr9N577yk3N1edOnXS0aNHC10nJiZGAQEB9iksLKwsDgEAALgJmzHGuLqI4njooYe0du1aff3116pbt26x18vOzlbz5s0VFRWl6dOnF9gmKytLWVlZ9tdpaWkKCwtTamqq/P39r7j2y1XET+0EACtwh08oLqmK+J5SVv2clpamgICAYr1/u/UYoDzjx4/XZ599pi1btpQo/EhSpUqVdN111+nAgQOFtvHx8ZGPj8+VlgkAACoIt74FZozR+PHjtWLFCn355ZeqX79+ibeRk5Oj77//XiEhIWVQIQAAqIjc+grQuHHj9P7772vVqlXy8/NTcnKyJCkgIECVK1eWJI0cOVLXXHONYmJiJEkvvviibrrpJjVq1EgpKSl67bXXdPjwYd1///0uOw4AAOBe3DoAzZs3T5LUo0cPh/mLFi3SqFGjJElJSUny8PjfhayzZ89q7NixSk5OVvXq1RUREaGtW7eqRYsW5VU2AABwc24dgIozPnvz5s0Or19//XW9/vrrZVQRAAC4Grj1GCAAAICyQAACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACW4+XqAgAAcBcDBri6ApQXrgABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLqRABaO7cuapXr558fX3VoUMH7dixo8j2y5cvV7NmzeTr66vWrVtrzZo15VQpAACoCNw+AC1btkwTJ07U1KlTtWvXLrVt21aRkZE6efJkge23bt2qqKgojRkzRrt379agQYM0aNAg/fDDD+VcOQAAcFc2Y4xxdRFF6dChg2688UbNmTNHkpSbm6uwsDA9/PDDeuqpp/K1v+uuu5SRkaHPPvvMPu+mm25Su3btNH/+/GLtMy0tTQEBAUpNTZW/v79zDuQP+LZhAICVrV5dNtstyfu3W18BunDhgnbu3KnevXvb53l4eKh3797atm1bgets27bNob0kRUZGFtoeAABYj5erCyjK6dOnlZOTozp16jjMr1Onjn7++ecC10lOTi6wfXJycqH7ycrKUlZWlv11amqqpEtJsixkZ5fJZgEAqBDK6O3V/r5dnJtbbh2AyktMTIxeeOGFfPPDwsJcUA0AAFe3gICy3f65c+cU8Cc7cesAVKtWLXl6eurEiRMO80+cOKHg4OAC1wkODi5Re0maMmWKJk6caH+dm5ur33//XTVr1pTNZruCI0BJpKWlKSwsTEeOHCmTsVcoGv3vOvS9a9H/ruPsvjfG6Ny5cwoNDf3Ttm4dgLy9vRUREaGNGzdq0KBBki6Fk40bN2r8+PEFrtOxY0dt3LhREyZMsM/bsGGDOnbsWOh+fHx85OPj4zAvMDDwSstHKfn7+/NLyIXof9eh712L/ncdZ/b9n135yePWAUiSJk6cqOjoaN1www1q37693njjDWVkZGj06NGSpJEjR+qaa65RTEyMJOnRRx9V9+7dNWvWLPXv319Lly5VfHy83nnnHVceBgAAcCNuH4DuuusunTp1Ss8//7ySk5PVrl07rVu3zj7QOSkpSR4e/3uYrVOnTnr//ff17LPP6umnn1bjxo21cuVKtWrVylWHAAAA3IzbByBJGj9+fKG3vDZv3pxv3rBhwzRs2LAyrgrO5uPjo6lTp+a7HYnyQf+7Dn3vWvS/67iy793+gxABAACcza0/CBEAAKAsEIAAAIDlEIAAAIDlEIAAAIDlEIDgNHPnzlW9evXk6+urDh06aMeOHYW23bdvn4YOHap69erJZrPpjTfeyNdmy5YtGjBggEJDQ2Wz2bRy5cp8bUaNGiWbzeYw9enTx4lHVXE4u/9jYmJ04403ys/PT7Vr19agQYOUkJDg0CYzM1Pjxo1TzZo1Va1aNQ0dOjTfJ7FbgSv6vkePHvnO/b/85S/OPrQKwdn9P2/ePLVp08b+4XwdO3bU2rVrHdpw7l/iir531rlPAIJTLFu2TBMnTtTUqVO1a9cutW3bVpGRkTp58mSB7c+fP68GDRpo5syZhX5NSUZGhtq2bau5c+cWue8+ffro+PHj9umDDz644uOpaMqi/+Pi4jRu3Dht375dGzZsUHZ2tm699VZlZGTY2zz22GNavXq1li9frri4OB07dkxDhgwpk2N0V67qe0kaO3asw7n/6quvOv343F1Z9H/dunU1c+ZM7dy5U/Hx8br55ps1cOBA7du3z96Gc991fS856dw3gBO0b9/ejBs3zv46JyfHhIaGmpiYmD9dNzw83Lz++utFtpFkVqxYkW9+dHS0GThwYAmrvfqUdf8bY8zJkyeNJBMXF2eMMSYlJcVUqlTJLF++3N7mp59+MpLMtm3bSn4QFZQr+t4YY7p3724effTR0pR8VSmP/jfGmOrVq5t//vOfxhjO/Tyu6HtjnHfucwUIV+zChQvauXOnevfubZ/n4eGh3r17a9u2bWW+/82bN6t27dpq2rSpHnroIZ05c6bM9+lOyqv/U1NTJUk1atSQJO3cuVPZ2dkO+23WrJmuvfbacvm5uwNX9X2eJUuWqFatWmrVqpWmTJmi8+fPO22fFUF59H9OTo6WLl2qjIwM+3dKcu67ru/zOOPcrxCfBA33dvr0aeXk5Ni/niRPnTp19PPPP5fpvvv06aMhQ4aofv36OnjwoJ5++mn17dtX27Ztk6enZ5nu212UR//n5uZqwoQJ6ty5s/1rZZKTk+Xt7Z3vi4Pr1Kmj5ORkp+zX3bmq7yVpxIgRCg8PV2hoqPbu3asnn3xSCQkJ+uSTT5yy34qgLPv/+++/V8eOHZWZmalq1appxYoVatGihSTOfcl1fS8579wnAKFCGz58uP3/W7durTZt2qhhw4bavHmzevXq5cLKri7jxo3TDz/8oK+//trVpVhOYX3/wAMP2P+/devWCgkJUa9evXTw4EE1bNiwvMu86jRt2lR79uxRamqqPvroI0VHRysuLs7hjRhl48/63lnnPrfAcMVq1aolT0/PfE9AnDhxotCBbmWlQYMGqlWrlg4cOFCu+3Wlsu7/8ePH67PPPtOmTZtUt25d+/zg4GBduHBBKSkpZbLfisBVfV+QDh06SBLnvpzT/97e3mrUqJEiIiIUExOjtm3b6s0335TEuS+5ru8LUtpznwCEK+bt7a2IiAht3LjRPi83N1cbN27Md9+2rB09elRnzpxRSEhIue7Xlcqq/40xGj9+vFasWKEvv/xS9evXd1geERGhSpUqOew3ISFBSUlJ5f5zdxVX9X1B9uzZI0mc+2X0uyc3N1dZWVmSOPcl1/V9QUp97l/xMGrAGLN06VLj4+NjYmNjzY8//mgeeOABExgYaJKTk40xxtx7773mqaeesrfPysoyu3fvNrt37zYhISFm8uTJZvfu3Wb//v32NufOnbO3kWRmz55tdu/ebQ4fPmxfPnnyZLNt2zaTmJhovvjiC3P99debxo0bm8zMzPLtABcri/5/6KGHTEBAgNm8ebM5fvy4fTp//ry9zV/+8hdz7bXXmi+//NLEx8ebjh07mo4dO5bfgbsBV/T9gQMHzIsvvmji4+NNYmKiWbVqlWnQoIHp1q1b+R68GyiL/n/qqadMXFycSUxMNHv37jVPPfWUsdlsZv369fY2nPuu6XtnnvsEIDjNP/7xD3Pttdcab29v0759e7N9+3b7su7du5vo6Gj768TERCMp39S9e3d7m02bNhXYJm8758+fN7feeqsJCgoylSpVMuHh4Wbs2LH2f3xW4+z+L2i5JLNo0SJ7m//+97/mr3/9q6levbqpUqWKGTx4sDl+/Hg5HK17Ke++T0pKMt26dTM1atQwPj4+plGjRubxxx83qamp5XTE7sXZ/X/fffeZ8PBw4+3tbYKCgkyvXr0cwo8xnPt5yrvvnXnu24wxpmTXjAAAACo2xgABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABuCps3rxZNpst3/czFWXatGlq165dmdUEwH0RgABUKNu2bZOnp6f69+/v6lIAVGAEIAAVyoIFC/Twww9ry5YtOnbsmKvLAVBBEYAAVBjp6elatmyZHnroIfXv31+xsbGFto2NjVVgYKBWrlypxo0by9fXV5GRkTpy5Ei+tv/6179Ur149BQQEaPjw4Tp37px92bp169SlSxcFBgaqZs2auu2223Tw4MGyODwA5YgABKDC+PDDD9WsWTM1bdpU99xzjxYuXKiivs7w/Pnzeumll/Tuu+/qm2++UUpKioYPH+7Q5uDBg1q5cqU+++wzffbZZ4qLi9PMmTPtyzMyMjRx4kTFx8dr48aN8vDw0ODBg5Wbm1tmxwmg7Hm5ugAAKK4FCxbonnvukST16dNHqampiouLU48ePQpsn52drTlz5qhDhw6SpMWLF6t58+basWOH2rdvL0nKzc1VbGys/Pz8JEn33nuvNm7cqJdeekmSNHToUIdtLly4UEFBQfrxxx/VqlWrsjhMAOWAK0AAKoSEhATt2LFDUVFRkiQvLy/dddddWrBgQaHreHl56cYbb7S/btasmQIDA/XTTz/Z59WrV88efiQpJCREJ0+etL/ev3+/oqKi1KBBA/n7+6tevXqSpKSkJGcdGgAX4AoQgAphwYIFunjxokJDQ+3zjDHy8fHRnDlzSr3dSpUqOby22WwOt7cGDBig8PBw/d///Z9CQ0OVm5urVq1a6cKFC6XeJwDX4woQALd38eJFvfvuu5o1a5b27Nljn7777juFhobqgw8+KHS9+Ph4++uEhASlpKSoefPmxdrvmTNnlJCQoGeffVa9evVS8+bNdfbsWaccEwDX4goQALf32Wef6ezZsxozZowCAgIclg0dOlQLFizQa6+9lm+9SpUq6eGHH9bf//53eXl5afz48brpppvs43/+TPXq1VWzZk298847CgkJUVJSkp566imnHBMA1+IKEAC3t2DBAvXu3Ttf+JEuBaD4+Hjt3bs337IqVaroySef1IgRI9S5c2dVq1ZNy5YtK/Z+PTw8tHTpUu3cuVOtWrXSY489VmDQAlDx2ExRz5ACQAUVGxurCRMmlOirMQBYB1eAAACA5RCAAACA5XALDAAAWA5XgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOUQgAAAgOX8PyORdNOF3MfGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Highest return if we ignore robustness: {max(alphas)}')\n",
    "\n",
    "# Create the histogram\n",
    "plt.hist(alphas, bins=10, alpha=0.7, color='blue')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Histogram of Feed Forward Model Alphas')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OhpnfVxELsKF",
   "metadata": {
    "id": "OhpnfVxELsKF"
   },
   "source": [
    "The highest alpha we could get if we ignore robustness is 0.135. Simply taking the highest alpha from a bunch of random trials would cause us to falsely believe our model is better than it is. This will lead to the model's average-case performance with real money on the market being far worse than our backtest expectations, which were based on a favorable random condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cReqpTcKxjl0",
   "metadata": {
    "id": "cReqpTcKxjl0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
